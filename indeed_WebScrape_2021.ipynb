{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Python Webscraping Indeed <font color=red>(Oct. 2021)</font> Revisit\n",
    "\n",
    "# `Mr Fugu Data Science:`\n",
    "\n",
    "# (◕‿◕✿)\n",
    "\n",
    "**Purpose & Outcome:**\n",
    "Webscrape Indeed: take position, job title,location,date of posting, string of qualifications\n",
    "\n",
    "Use a list of words related to your skills or skills you are interested in and extract from job post qualifications section.\n",
    "\n",
    "Date time formating\n",
    "\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests         # grab web-page\n",
    "from bs4 import BeautifulSoup as bsopa  # parse web-page\n",
    "import datetime         # format date/time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ex.) https://www.indeed.com/jobs?q=data+scientist&l=california&start=10\n",
    "\n",
    "range(0,150,10): each page will have \"start=0,start=10,start=20 etc\" which deals with\n",
    "going through each page, but not exactly 10 entries/pg. \n",
    "\n",
    "string formatting is used to denote what job and location we want: you can use a string\n",
    "separated by space and it will be interpreted by the website. \n",
    "\n",
    "sou=bsopa(y.text,'lxml') is taking our get request and converting to text in the format\n",
    "of 'lxml' but we can replace with 'html.parser' as well.\n",
    "\n",
    "Each job post can be parsed by the 'div',{\"class\":\"jobsearch-SerpJobCard\"} or \n",
    "'div', {'class': 'row'} depending on how you want to search\n",
    "\n",
    "After that we get each piece of information we want to obtain: job title, location etc.\n",
    "\n",
    "the only difficult and frustrating part is getting all the raw text for each posting\n",
    "relating to the qulifications. We have to open a link, iterate through it and then extract\n",
    "all the information with a try/except block and then further process.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Original Code October 2020'"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Original Code October 2020'''\n",
    "\n",
    "# gg=[]\n",
    "# for j in range(0,150,10):\n",
    "#     position,location='data scientist','california'\n",
    "#     y=requests.get('https://www.indeed.com/jobs?q={}&l={}&sort=date='.format(position,location)+str(j))\n",
    "\n",
    "#     # y=requests.get('https://www.indeed.com/jobs?q=data+scientist&l=california&sort=date='+str(i))\n",
    "#     sou=bsopa(y.text,'lxml')\n",
    "\n",
    "# #     for ii in sou.find_all('div', {'class': 'row'}):\n",
    "#     for ii in sou.find_all('div',{\"class\":\"jobsearch-SerpJobCard\"}):\n",
    "#         print(ii)\n",
    "\n",
    "#         job_title = ii.find('a', {'data-tn-element': 'jobTitle'})['title']\n",
    "#         company_name = ii.find('span', {'class': 'company'}).text.strip()    \n",
    "#         location=ii.find('span',{\"class\":\"location\"})\n",
    "#         post_date = ii.find('span', attrs={'class': 'date'})\n",
    "#         summary=ii.find('div',attrs={'class':'summary'})\n",
    "\n",
    "#         if location:\n",
    "#             location=location.text.strip()\n",
    "#         else:\n",
    "#             location=ii.find('div',{\"class\":\"location\"})\n",
    "#             location=location.text.strip()\n",
    "\n",
    "#         k=ii.find('h2', {'class':\"title\"})\n",
    "#         p=k.find(href=True)\n",
    "#         v=p['href']\n",
    "#         f_=str(v).replace('&amp;','&') # links to iterate for qualification text\n",
    "        \n",
    "        \n",
    "#         datum = {'job_title': job_title,\n",
    "#                     'company_name': company_name,\n",
    "#                     'location': location,\n",
    "#                     'summary':summary.text.strip(),\n",
    "#                     'post_Date':post_date.text,\n",
    "#                     'Qualification_link': f_}\n",
    "\n",
    "#         print(datum)\n",
    "#         gg.append([location,job_title,company_name,post_date.text,summary.text.strip()\n",
    "# #                   ,f_]) \n",
    "#         gg.append(datum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the original piece of code that was used until about Summer of 2020, you were able to parse from the outer most section using the 'jobsearch-SerpJobCard'. We were iterating over each of these because it was the start of a new job posting and inside of it were the details to extract.\n",
    "\n",
    "`for ii in sou.find_all('div', {'class': 'row'}):\n",
    "     for ii in sou.find_all('div',{\"class\":\"jobsearch-SerpJobCard\"}):\n",
    "         print(ii)`\n",
    "         \n",
    "Here we are just extracting everything we need, the 'jobtile' is subset to go inside and get information using the brackets you see. Then we have to get the company name which with then be parsed by stripping the text from html. Location was different because you will need conditional statements based on if you see it or not and have to do comparisons by 2 different text blocks.  The rest of this is straight forward.\n",
    "\n",
    "     job_title = ii.find('a', {'data-tn-element': 'jobTitle'})['title']\n",
    "     company_name = ii.find('span', {'class': 'company'}).text.strip()    \n",
    "     location=ii.find('span',{\"class\":\"location\"})\n",
    "     post_date = ii.find('span', attrs={'class': 'date'})\n",
    "     summary=ii.find('div',attrs={'class':'summary'})\n",
    "\n",
    "Now, get the tile from the href which store hyperlinks and we will need to store those links to get job description which will be on a separate paged link. That link will be the entire posting not the snapshot seen as a glance. \n",
    "     \n",
    "     k=ii.find('h2', {'class':\"title\"})\n",
    "     p=k.find(href=True)\n",
    "     v=p['href']\n",
    "     f_=str(v).replace('&amp;','&') # links to iterate for qualification text\n",
    "\n",
    "Store everything as a dictionary for ease of use later.\n",
    "\n",
    "     datum = {'job_title': job_title,\n",
    "                 'company_name': company_name,\n",
    "                 'location': location,\n",
    "                 'summary':summary.text.strip(),\n",
    "                 'post_Date':post_date.text,\n",
    "                 'Qualification_link': f_}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `New Version Oct. 2021`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senior Data Scientist - Ads Optimization\n",
      "Indeed\n",
      "Nope\n",
      "Sunnyvale, CA 94086 (Washington area)+1 location•Temporarily Remote\n",
      "Associate, Operations Research Data Scientist\n",
      "KPMG\n",
      "Nope\n",
      "Los Angeles, CA 90071 (Downtown area)+2 locations\n",
      "Associate, Data Scientist\n",
      "KPMG\n",
      "Nope\n",
      "Los Angeles, CA 90071 (Downtown area)+2 locations\n",
      "Data Scientist I\n",
      "Inland Empire Health Plans\n",
      "Nope\n",
      "Rancho Cucamonga, CA 91730\n",
      "Data Scientist\n",
      "Cymbiotika\n",
      "Nope\n",
      "San Diego, CA 92121 (Torrey Preserve area)\n",
      "People Analytics Data Scientist\n",
      "Workday\n",
      "Nope\n",
      "Pleasanton, CA\n",
      "Data Scientist\n",
      "Doorstead\n",
      "Nope\n",
      "San Francisco, CA•Remote\n",
      "Data Scientist, Monetization\n",
      "TikTok\n",
      "Nope\n",
      "Mountain View, CA 94041 (Old Mountain View area)\n",
      "Associate Data Scientist\n",
      "Activision\n",
      "Nope\n",
      "Santa Monica, CA\n",
      "Data Scientist (remote)\n",
      "Fitbod\n",
      "Nope\n",
      "San Francisco, CA•Remote\n",
      "Senior Data Scientist - Ads Optimization\n",
      "Indeed\n",
      "$153,000 - $223,000 a year\n",
      "Sunnyvale, CA 94086 (Washington area)+1 location•Temporarily Remote\n",
      "Associate, Data Scientist\n",
      "KPMG\n",
      "Nope\n",
      "San Francisco, CA 94105 (South Beach area)+8 locations\n",
      "Data Scientist I\n",
      "Inland Empire Health Plans\n",
      "$97,843 - $124,758 a year\n",
      "Rancho Cucamonga, CA 91730+1 location\n",
      "Data Scientist\n",
      "Cymbiotika\n",
      "$50,000 - $60,000 a year\n",
      "San Diego, CA 92121 (Torrey Preserve area)\n",
      "People Analytics Data Scientist\n",
      "Workday\n",
      "Nope\n",
      "Pleasanton, CA\n",
      "Data Scientist\n",
      "Doorstead\n",
      "Nope\n",
      "San Francisco, CA•Remote\n",
      "Associate Data Scientist\n",
      "Activision\n",
      "Nope\n",
      "Santa Monica, CA+1 location\n",
      "Data Scientist (remote)\n",
      "Fitbod\n",
      "Nope\n",
      "San Francisco, CA•Remote\n",
      "Data Scientist - Entry Level\n",
      "Lawrence Livermore National Laboratory\n",
      "Nope\n",
      "Livermore, CA 94550+2 locations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KEEP THIS VERSION: October 2021\n",
    "\n",
    "gg=[]\n",
    "for j in range(0,15,10): # calling 15 entries\n",
    "    \n",
    "    position,location='data scientist','california'\n",
    "    \n",
    "    y=requests.get('https://www.indeed.com/jobs?q={}&l={}&sort=date='.format(position,location)+str(j))\n",
    "#     print(y)\n",
    "\n",
    "    sou=bsopa(y.text,'lxml')\n",
    "    \n",
    "#     print(sou) use this if you want to check if working properly, response code 200\n",
    "\n",
    "\n",
    "    for ii in sou.find_all('div',{\"class\":\"job_seen_beacon\"}):\n",
    "        j=ii.find('tbody') # calling the table body to go inside of\n",
    "        a= j.find('tr') # going inside the table\n",
    "\n",
    "\n",
    "    #             print(len(wa_))\n",
    "\n",
    "        for n in a.find_all('h2',{'class':'jobTitle jobTitle-color-purple jobTitle-newJob'}):\n",
    "            job_title=n.find_all('span')[1].get_text()# if you don't use the 1, you get the 'new' posting text\n",
    "            print(job_title)\n",
    "        # Company Name is in new nesting:\n",
    "    #             print(a.find_all('span',{'class':'companyName'}))\n",
    "\n",
    "            other=a.find('div',{'class':'heading6 company_location tapItem-gutter'})\n",
    "            pr_=other.find('span')\n",
    "            company_=(pr_.get_text())\n",
    "            print(company_) \n",
    "            gg.append(company_)\n",
    "    #             print(a.find('span',{'class':'companyName'}).get_text()) # alt version\n",
    "\n",
    "        # Salary if available:\n",
    "            if a.find('div',{'class':'heading6 tapItem-gutter metadataContainer noJEMChips salaryOnly'}):\n",
    "                print(a.find('div',{'class':'metadata salary-snippet-container'}).get_text())\n",
    "    #                 print(a.find('div',{'class':'heading6 tapItem-gutter metadataContainer noJEMChips salaryOnly'}))\n",
    "            else:\n",
    "                print('Nope')\n",
    "\n",
    "\n",
    "            # Location:\n",
    "        #             locaiton=(other.find('div',{'class':'companyLocation'})) # checking something\n",
    "        #             print(other.find('pre').get_text()) # good start\n",
    "            opt_1=other.find('pre')\n",
    "            print(opt_1.find('div',{'class':'companyLocation'}).get_text())\n",
    "len(gg)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Final Deal:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Indeed',\n",
       "  'Sunnyvale, CA 94086 (Washington area)+1 location•Temporarily Remote',\n",
       "  '$153,000 - $223,000 a year',\n",
       "  'Senior Data Scientist - Ads Optimization',\n",
       "  '/pagead/clk?mo=r&ad=-6NYlbfkN0CiRNM7CVr8YueLFKlzwbFWI0o7IjV438l4sVrvKZ0flkywQJjHRBleObb6D711MbmS4ls7d3cF2Oq3aULRL-oCpslQ8eol1sCeCsrHu6Ormuhl_Gd2n_2z30mgTt9HyPd0R2YWYjvrQpCS5p1j9c2ZMxHpmr7PLcQ4RrnjcUQoSJEU1n8kwuSkPjjkuu0YCQ5pB3Q4pg8cBuCYb4C7rlTo8tjCITIibgEDN6U1ijuTr2905NcR87ipsT6pqVEYHp0FOb4ZT2XTE3pQji3sGUO62A6fg0SR_NaGly2iAUveSV1QohOdfN1Qcc4ilZe9m74YDGggllE1rhLrOrkpk2qwb7v0t8jBvtqb8S52e5ccYcXC2Z6vSY03iF6QfmmWj42gTn9_20rrIwkrAuVrztIdYjjZGzuMm6F8OdT71-8faWpL1g4secQ2-uj2cZrj483DW_1_9PsSvHpfe40eIAtN07K6e3mMNu2WnsG50LAdjghwXoxZp1_WcjlaDgbrqHe1L3EVcqz2VXbRbHAdXyK_7K8q-_efLULxW9SfiKnOwhPTpYeI8OVX&p=1&fvj=0&vjs=3'],\n",
       " ['KPMG',\n",
       "  'San Francisco, CA 94105 (South Beach area)+8 locations',\n",
       "  'No Salary posted',\n",
       "  'Associate, Data Scientist',\n",
       "  '/pagead/clk?mo=r&ad=-6NYlbfkN0CzN6uX84z9wq8HaOCWH9ZvJLeemKyVc3gCGVrPSg-ucI9H6BgA8rDcXux5vfMF3jfPLAcL_8mkTIxyarZP1sq9-tD0-jA3Y6WEfxnyBIiuGY-_po0tLUjvXnqhfH2tUVrboycwnykVqCjY77bPCmJYbAO9x67OtsivC-UDrXrdDFqZFrF4LWc7RsVYowfeI06NUqjNlxXUxNYJJaVlaYbD04lqWa-tyyIenKOtpr2SWTPvlZR0Ddl7CC3NO0TG7PIwjZ8ElFnHS59voq1EG6odVpAPmUyA2ef5HevNwwH7paqkgQYJLvqCHLzr2NnEac7tGI0cFYz6dvOtHmnF8zGOlzqFbVTTZ0jIzxx8uVCaeUj4lLJtT_IwTelTw1qO3CL-XQfv4t0YZWV0v0mSuqZSqAReAvNM6ROL0ls_4WRlGCET0Uv-2kkKSnfHZKYgRf7AqrSfSWhS7sSJV40g7nH3hLBVLwz7ogO30Cfj4klqj_tto3SXfOqc0FoynxD201oDGooR8aoR81Jo9f7zkMjXQrVALkXvrMhf6w-IeGevYu6tXwN1LCB0seCqSNeIV0IwxyvyiI5BNtX3VuOpZ8sxqtLwOzAqbRi8AZu88ItiIRTSKDQE48_6fXkibOUyJRbENVyh1KFuS41qODE3-BNLH_Xn6n-0jjbo8gw_fKPhwQW4wfGI8oVInX2bB6H_3J8nBVELOep4QxSMg1_i2tnuCbhMTmCMLticJF3o0hJWGcJ-9VZOGYS5FjXLSUjSs2LPmM2tAUtHJNzuLKnA2FK2EviYQPYYBad9xY7rI8TgjU_om7Sk-zbAhUgn1d03KG_qQC6GNroh3Ak0Tsc-AFiCE6y28fAERWQOff4Q1TPElOJhT8VMqJN6c2tw8D75NFcX4DErj9WVGZ9kj8pB1LlrinWsOqwexH_zaQEeXlHp3_ev88O9U6Y_k1zG-V2aoDJklPDCNMfuSF5uU8oE00w5278NfXXuJ5GiyH8f8NfXhIM4nkSuM_NJRf7AkWuDQ0FrxvCI31qX50H_ss8vfLCRS_bABDDB6pi1Ta_z-G8_yo6V6gKqlISS6t_0-NbH1ohjlfbs0fS3oQ==&p=2&fvj=0&vjs=3'],\n",
       " ['Inland Empire Health Plans',\n",
       "  'Rancho Cucamonga, CA 91730+1 location',\n",
       "  '$97,843 - $124,758 a year',\n",
       "  'Data Scientist I',\n",
       "  '/rc/clk?jk=4edcc9b6df92924e&fccid=f23cfaf12528dbd0&vjs=3'],\n",
       " ['Cymbiotika',\n",
       "  'San Diego, CA 92121 (Torrey Preserve area)',\n",
       "  '$50,000 - $60,000 a year',\n",
       "  'Data Scientist',\n",
       "  '/company/Cymbiotika/jobs/Data-Scientist-2832b48c155fc4e4?fccid=0dfc05f77847bd48&vjs=3'],\n",
       " ['Workday',\n",
       "  'Pleasanton, CA',\n",
       "  'No Salary posted',\n",
       "  'People Analytics Data Scientist',\n",
       "  '/rc/clk?jk=a50f913cb24519cc&fccid=9ac45d217f8342a1&vjs=3'],\n",
       " ['Doorstead',\n",
       "  'San Francisco, CA•Remote',\n",
       "  'No Salary posted',\n",
       "  'Data Scientist',\n",
       "  '/rc/clk?jk=7b9bca069f86f278&fccid=0571d4e0d8a49b91&vjs=3'],\n",
       " ['Activision',\n",
       "  'Santa Monica, CA+1 location',\n",
       "  'No Salary posted',\n",
       "  'Associate Data Scientist',\n",
       "  '/rc/clk?jk=a0480b289c939f61&fccid=71147e0539a0a1b7&vjs=3'],\n",
       " ['Fitbod',\n",
       "  'San Francisco, CA•Remote',\n",
       "  'No Salary posted',\n",
       "  'Data Scientist (remote)',\n",
       "  '/rc/clk?jk=b6a78ada05d6a311&fccid=c01c2bfafd4dbb57&vjs=3'],\n",
       " ['Lawrence Livermore National Laboratory',\n",
       "  'Livermore, CA 94550+2 locations',\n",
       "  'No Salary posted',\n",
       "  'Data Scientist - Entry Level',\n",
       "  '/rc/clk?jk=3ffb79b589d7ea3e&fccid=26727f1861532c63&vjs=3']]"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ouch_=[]\n",
    "for ii in sou.find_all('tbody'):\n",
    "\n",
    "    pri=ii.find('tr')\n",
    "#     print(pri)\n",
    "    for wows in pri.find_all('a',href=True):\n",
    "        if wows.find('a',href=True):\n",
    "            wawa.append(wows['href'])\n",
    "    # Links for job description:\n",
    "            yikes=wows['href']\n",
    "        \n",
    "    # Get job title, location, salary\n",
    "            for ii_ in wows.find_all('div',{\"class\":\"job_seen_beacon\"}):\n",
    "                j=ii_.find('tbody') # calling the table body to go inside of\n",
    "                a= j.find('tr') # going inside the table\n",
    "\n",
    "                for n in a.find_all('h2',{'class':'jobTitle jobTitle-color-purple jobTitle-newJob'}):\n",
    "                    \n",
    "            # Job Title:\n",
    "                    job_title=n.find_all('span')[1].get_text()# if you don't use the 1, you get the 'new' posting text\n",
    "            \n",
    "            # Company Name\n",
    "#                     Company Name is in new nesting:\n",
    "\n",
    "                    other=a.find('div',{'class':'heading6 company_location tapItem-gutter'})\n",
    "                    pr_=other.find('span')\n",
    "                    company_=(pr_.get_text())\n",
    "            \n",
    "            \n",
    "#                     print(company_) \n",
    "#                     gg.append(company_)\n",
    "            #             print(a.find('span',{'class':'companyName'}).get_text()) # alt version\n",
    "\n",
    "                # Salary if available:\n",
    "                    if a.find('div',{'class':'heading6 tapItem-gutter metadataContainer noJEMChips salaryOnly'}):\n",
    "                        salary=a.find('div',{'class':'metadata salary-snippet-container'}).get_text()\n",
    "#             #                 print(a.find('div',{'class':'heading6 tapItem-gutter metadataContainer noJEMChips salaryOnly'}))\n",
    "                    else:\n",
    "                        salary='No Salary posted'\n",
    "\n",
    "\n",
    "                # Location:\n",
    "                    opt_1=other.find('pre')\n",
    "                    location=opt_1.find('div',{'class':'companyLocation'}).get_text()\n",
    "                \n",
    "                \n",
    "                \n",
    "                    ouch_.append([company_,location,salary,job_title,yikes])\n",
    "ouch_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
