{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a55bed64",
   "metadata": {},
   "source": [
    "# `Selenium Webscraping Indeed Job Postings - July 2023`\n",
    "\n",
    "# <font color=red>Mr Fugu Data Science</font>\n",
    "\n",
    "# (◕‿◕✿)\n",
    "\n",
    "# `Purpose & Outcome:`\n",
    "\n",
    "+ Webscrape Indeed Postings\n",
    "+ Methods, drawbacks and suggestions\n",
    "+ Speeding up code and downsides with this method!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf01d1",
   "metadata": {},
   "source": [
    "# `What is Selenium and how is it used?`\n",
    "\n",
    "+ When you need to do unit testing, automation or assistance when webscraping this is a tool to aid you.\n",
    "    + Great for clicking buttons\n",
    "    + drop-down menus\n",
    "    + acting/emulating human interactions on a webpage\n",
    "  \n",
    "+ `You can use Selenium as a webscraper but, its not fast and will help if you are in a pinch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "653f45f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if you have never used these: unblock the lines below to install if needed\n",
    "\n",
    "# !pip install webdriver-manager\n",
    "# !pip3 install lxml\n",
    "# !pip3 install selenium\n",
    "# !pip3 install webdriver_manager\n",
    "# !pip install --upgrade pip\n",
    "# !pip install -U selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d754db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- import necessary modules -------\n",
    "\n",
    "# For webscraping\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Parsing and creating xml data\n",
    "from lxml import etree as et\n",
    "\n",
    "# Store data as a csv file written out\n",
    "from csv import writer\n",
    "\n",
    "# In general to use with timing our function calls to Indeed\n",
    "import time\n",
    "\n",
    "# Assist with creating incremental timing for our scraping to seem more human\n",
    "from time import sleep\n",
    "\n",
    "# Dataframe stuff\n",
    "import pandas as pd\n",
    "\n",
    "# Random integer for more realistic timing for clicks, buttons and searches during scraping\n",
    "from random import randint\n",
    "\n",
    "# Multi Threading\n",
    "import threading\n",
    "\n",
    "# Threading:\n",
    "from concurrent.futures import ThreadPoolExecutor, wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bee43e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.10.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "\n",
    "# Check version I am running\n",
    "selenium.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "ba65a234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium 4:\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "# Starting/Stopping Driver: can specify ports or location but not remote access\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "\n",
    "# Manages Binaries needed for WebDriver without installing anything directly\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "8f41e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows searchs similar to beautiful soup: find_all\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Try to establish wait times for the page to load\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "# Wait for specific condition based on defined task: web elements, boolean are examples\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Used for keyboard movements, up/down, left/right,delete, etc\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# Locate elements on page and throw error if they do not exist\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0c820c",
   "metadata": {},
   "source": [
    "# `Consider Headless Browser: speed up & uses less resources`\n",
    "\n",
    "There are some condiserations though:\n",
    "\n",
    "+ Some browsers create issues\n",
    "+ debugging can be tricky\n",
    "+ you may have limited plugin usage or support\n",
    "+ you are not able to see visually how the website or application are working \n",
    "\n",
    "`-------------------------------------------------`\n",
    "\n",
    "# `from selenium.webdriver.common.by import By`\n",
    "\n",
    "Think of this as being similar to using `Beautiful Soup and find_all`\n",
    "+ when used it allows you to find something within an HTML document, if it fails you raise the exception: `NoSuchElementException`\n",
    "+ **`Becareful when using BY`** because if this is not a static page then any attrubutes you are searching can become an error in the future when it fails.\n",
    "    + For example if you are searching by `Class` this can create issues later vs using\n",
    "        + This is because it is a `CSS` selector and can change overtime since it is an attribute\n",
    "    + `ID` which may make your code more robust! This CAN be a unique identifier that may help you instead\n",
    "\n",
    "# `NoSuchElementException`\n",
    "\n",
    "This is useful to locate elements within a page while loading and try to handle exceptions.\n",
    "+ During `AJAX` calls you may have issues if the application was build using `React, VUE, Angular` and require different use cases to make the above checks. [article to explain](https://reflect.run/articles/everything-you-need-to-know-about-nosuchelementexception-in-selenium/) and you can consider polling.\n",
    "\n",
    "`-------------------------------------------------`\n",
    "\n",
    "# `Other Common Errors:`\n",
    "\n",
    "+ **`InvalidSelectorException`**\n",
    "\n",
    "+ **`ElementNotInteractableException`**\n",
    "\n",
    "+ **`TimeoutException`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d6c62cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows you to cusotmize: ingonito mode, maximize window size, headless browser, disable certain features, etc\n",
    "option= webdriver.ChromeOptions()\n",
    "\n",
    "# Going undercover:\n",
    "option.add_argument(\"--incognito\")\n",
    "\n",
    "\n",
    "# # Consider this if the application works and you know how it works for speed ups and rendering!\n",
    "\n",
    "# option.add_argument('--headless=chrome')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "ae3a9129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/jobs?q={}&l={}&radius=35&filter=0&sort=date&start={}\n"
     ]
    }
   ],
   "source": [
    "# Define job and location search keywords\n",
    "job_search_keyword = ['Data+Scientist', 'Business+Analyst', 'Data+Engineer', \n",
    "                      'Python+Developer', 'Full+Stack+Developer', \n",
    "                      'Machine+Learning+Engineer']\n",
    "\n",
    "# Define Locations of Interest\n",
    "location_search_keyword = ['New+York', 'California', 'Washington']\n",
    "\n",
    "# Finding location, position, radius=35 miles, sort by date and starting page\n",
    "paginaton_url = 'https://www.indeed.com/jobs?q={}&l={}&radius=35&filter=0&sort=date&start={}'\n",
    "\n",
    "# print(paginaton_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30276a3f",
   "metadata": {},
   "source": [
    "# `Things to consider when scraping data:`\n",
    "\n",
    "+ Wait for page to load before we start running tasks\n",
    "+ make sure what we are looking for is actually there\n",
    "    + It can be absent\n",
    "    + hidden in DOM, iframe or similar\n",
    "+ timing our calls to remain more like an average user\n",
    "+ Exception handling\n",
    "\n",
    "`----------------------------------------------`\n",
    "\n",
    "# `I/O vs CPU Bound:`\n",
    "\n",
    "**`During webscraping tasks you are I/O bound!`** you are making calls to retreive `HTML`. Try to avoid unnecessary calls which may get your IP Address blocked like I have many times. [CPU, I/O article](https://testdriven.io/blog/concurrency-parallelism-asyncio/)\n",
    "\n",
    "+ **`Multi-Threading:`** `concurrent`\n",
    "    + Your tasks will not run parrallel here and they run one after another. \n",
    "    + If something is waiting or slow it can start working on another task and will be asynchronous\n",
    "        + Meaning that you can have tasks out of order and not 1-2-3 but maybe 0-2-3-1 for example of order\n",
    "        + This can occur due to Network or I/O operations\n",
    "+ **`Multi-Processing:`** `parrallel`\n",
    "\n",
    "+ **`AsyncIO:`** benefit of threading but not worrying about wait times and running more tasks during a wait time.\n",
    "This is a step above the threading from above but requires more code and thought to setup.\n",
    "\n",
    "`----------------------------------------------`\n",
    "\n",
    "+ **`Asynchronous:`** think of running one task and then calling the next task before the first task has finished. This happens when you send a response but don't receive an answer so you go to the next person in line and when you are free and have a response from prior person you then go ahead and help them. Essentially, lowering the idle time of waiting for a response. [Good breakdown and visuals](https://medium.com/analytics-vidhya/asynchronous-web-scraping-101-fetching-multiple-urls-using-arsenic-ec2c2404ecb4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf0119",
   "metadata": {},
   "source": [
    "# `Let's look at what is going on below:`\n",
    "\n",
    "There are some concerns and things for you to consider:\n",
    "\n",
    "1.) Below is the MAX number of jobs you will find for a posting of interest!\n",
    "\n",
    "2.) This is not an accurate depiction because you can have way less than this depending on results\n",
    "    \n",
    "    + An issue arises due to duplicated listings\n",
    "\n",
    "3.) Pagination is difficult to do and when to stop the search results\n",
    "\n",
    "4.) you have a filter option (&filter=0, &filter=1), filter =1 shows non-duplicates which reduces results but you need to figure out how to do pagination!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef86145",
   "metadata": {},
   "source": [
    "`---------------------------------------------------------------`\n",
    "\n",
    "# `First let's try to find number of jobs for a given posting`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "07d8435e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.784760236740112 seconds to complete action!\n",
      "-----------------------\n",
      "Max Iterable Pages for this search: 11\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "job_='Data+Engineer'\n",
    "location='Washington'\n",
    "\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()),\n",
    "                         options=option)\n",
    "\n",
    "\n",
    "driver.get(paginaton_url.format(job_,location,0))\n",
    "\n",
    "# t = ScrapeThread(url_)\n",
    "# t.start()\n",
    "\n",
    "sleep(randint(2, 6))\n",
    "\n",
    "p=driver.find_element(By.CLASS_NAME,'jobsearch-JobCountAndSortPane-jobCount').text\n",
    "\n",
    "# Max number of pages for this search! There is a caveat described soon\n",
    "max_iter_pgs=int(p.split(' ')[0])//15 \n",
    "\n",
    "\n",
    "driver.quit() # Closing the browser we opened\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(end - start,'seconds to complete action!')\n",
    "print('-----------------------')\n",
    "print('Max Iterable Pages for this search:',max_iter_pgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28da6c73",
   "metadata": {},
   "source": [
    " \n",
    "`----------------------------------------------------------` \n",
    " \n",
    "# Notes for this project:\n",
    "\n",
    "+ Filling in forms:\n",
    "+ click buttons\n",
    "+ possible human detection stuff\n",
    "\n",
    "**`Xpath vs CSS selectors for retreiving data`**\n",
    "\n",
    "+ `Xpath:` bidirectional (can go from parent to child and reverse) traversal\n",
    "    + slower retrevial speed\n",
    "    + text functions supported\n",
    "    + pay attention to relative '//' and absolute path '/' notations\n",
    "    + Think of a tree like structure to breakdown\n",
    "+ `CSS:` directional (parent to child only)\n",
    "\n",
    "`------------------------`\n",
    "\n",
    "**`Xpath`**\n",
    "+ *`Xpath`* stands for `XML Path` which is a query language used to find the path of an element in XML documents\n",
    "+ Essentially you are navigating a `DOM` \n",
    "+ More flexible than using `CSS`\n",
    "    + If you don't know the name of an element you can use `contains` as your key word which is great!\n",
    " \n",
    "**`CSS`**\n",
    "+ Most often the HTML will be styled in a cascading format and identifying elements will come from the `Class` they fall within\n",
    "+ They are used to select various elements within a `DOM`\n",
    "    + **`Simple selectors:`** such as finding a `Class` or `ID`\n",
    "    + **`Attribute selectors:`** \n",
    "    + **`Pseudo selectors:`** such as hover boxes or check boxes as examples\n",
    "    \n",
    "# `Wait times: ` because of how webpages are rendered you will/can have various items loading at different times. \n",
    "This can be a problem when you are webscraping. If you try to grab the elements too fast you can miss something or \n",
    "cause errors to occur which could have been avoided. \n",
    "\n",
    "Ways to combat this can include explicit waits within Selenium such as [selenium doc](https://selenium-python.readthedocs.io/waits.html) \n",
    "\n",
    "`from selenium.webdriver.support.wait import WebDriverWait`\n",
    "\n",
    "`from selenium.webdriver.support import expected_conditions as EC`\n",
    "\n",
    "`----------------------------------------------------------------------`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "d0a53efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.44914388656616 seconds to complete Query!\n"
     ]
    }
   ],
   "source": [
    "# Pagination: PRACTICE\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "job_='Data+Engineer'\n",
    "location='Washington'\n",
    "\n",
    "\n",
    "job_lst=[]\n",
    "job_description_list_href=[]\n",
    "\n",
    "# job_description_list = []\n",
    "salary_list=[]\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()),\n",
    "                         options=option)\n",
    "sleep(randint(2, 6))\n",
    "\n",
    "# driver.get(\"https://www.indeed.com/q-USA-jobs.html\")\n",
    "\n",
    "for i in range(0,max_iter_pgs):\n",
    "    driver.get(paginaton_url.format(job_,location,i*10))\n",
    "    \n",
    "    \n",
    "    sleep(randint(2, 4))\n",
    "\n",
    "    job_page = driver.find_element(By.ID,\"mosaic-jobResults\")\n",
    "    jobs = job_page.find_elements(By.CLASS_NAME,\"job_seen_beacon\") # return a list\n",
    "\n",
    "    for jj in jobs:\n",
    "        job_title = jj.find_element(By.CLASS_NAME,\"jobTitle\")\n",
    "#         print(job_title.text)\n",
    "        \n",
    "# Href's to get full job description (need to re-terate to get full info)\n",
    "# Reference ID for each job used by indeed         \n",
    "# Finding the company name        \n",
    "# Location\n",
    "# Posting date\n",
    "# Job description\n",
    "\n",
    "        job_lst.append([job_title.text,\n",
    "        job_title.find_element(By.CSS_SELECTOR,\"a\").get_attribute(\"href\"),\n",
    "        job_title.find_element(By.CSS_SELECTOR,\"a\").get_attribute(\"id\"),      \n",
    "        jj.find_element(By.CLASS_NAME,\"companyName\").text,       \n",
    "        jj.find_element(By.CLASS_NAME,\"companyLocation\").text,\n",
    "        jj.find_element(By.CLASS_NAME,\"date\").text,\n",
    "        job_title.find_element(By.CSS_SELECTOR,\"a\").get_attribute(\"href\")])\n",
    "        \n",
    "\n",
    "        try: # I removed the metadata attached to this class name to work!\n",
    "            salary_list.append(jj.find_element(By.CLASS_NAME,\"salary-snippet-container\").text)\n",
    "\n",
    "        except NoSuchElementException: \n",
    "            try: \n",
    "                salary_list.append(jj.find_element(By.CLASS_NAME,\"estimated-salary\").text)\n",
    "                \n",
    "            except NoSuchElementException:\n",
    "                salary_list.append(None)\n",
    "      \n",
    "                \n",
    "#         # Click the job element to get the description\n",
    "#         job_title.click()\n",
    "        \n",
    "#         # Help to load page so we can find and extract data\n",
    "#         sleep(randint(3, 5))\n",
    "\n",
    "#         try: \n",
    "#             job_description_list.append(driver.find_element(By.ID,\"jobDescriptionText\").text)\n",
    "            \n",
    "#         except: \n",
    "            \n",
    "#             job_description_list.append(None)\n",
    "\n",
    "driver.quit() \n",
    "\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(end - start,'seconds to complete Query!')\n",
    "\n",
    "# alternate way to grab the info for job description to make it faster:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "49414e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Data Engineer- W2 and onsite-(No C2C Candidates)',\n",
       "  'https://www.indeed.com/company/Aalpha-Tech-Global/jobs/Data-Engineer-0a3b693beb4513a1?fccid=446617e52fa5726d&vjs=3',\n",
       "  'job_0a3b693beb4513a1',\n",
       "  'Aalpha Tech Global',\n",
       "  'Seattle, WA 98101 \\n(Downtown area)',\n",
       "  'Posted\\nJust posted',\n",
       "  'https://www.indeed.com/company/Aalpha-Tech-Global/jobs/Data-Engineer-0a3b693beb4513a1?fccid=446617e52fa5726d&vjs=3'],\n",
       " ['Data and Analytics Engineer - Senior Associate',\n",
       "  'https://www.indeed.com/rc/clk?jk=f649d5700cf3da4d&fccid=5e964c4afc56b180&vjs=3',\n",
       "  'job_f649d5700cf3da4d',\n",
       "  'PRICE WATERHOUSE COOPERS',\n",
       "  'Seattle, WA 98101 \\n(Downtown area)',\n",
       "  'Posted\\nToday',\n",
       "  'https://www.indeed.com/rc/clk?jk=f649d5700cf3da4d&fccid=5e964c4afc56b180&vjs=3']]"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_lst[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "305fb0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Estimated $101K - $128K a year',\n",
       " 'Estimated $117K - $148K a year',\n",
       " 'Estimated $114K - $145K a year']"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_list[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cf38ec",
   "metadata": {},
   "source": [
    "# `Here is a side note:`\n",
    "\n",
    "\n",
    "+ This gives me an error because it was code from the past version:\n",
    "\n",
    "`driver = webdriver.Chrome(ChromeDriverManager().install())`\n",
    "\n",
    "\n",
    "+ `When using ingonito browser:` your browsing tabs will pull different data than a normal window. Understand this when doing your troubleshooting and debugging. If you have a window open to find your tags but parse in a different type of window the results will not line up.\n",
    "\n",
    "+ Also, when you are grabbing `job descriptions` for example you will need to time it so the page will read the data after it is loaded. If you immediately try to grab data you may not get everything!\n",
    "    + Option 1: use the clickable tab from the `job title` then scrape directly\n",
    "    + Option 2: consider saving the `HREF's` and then doing a separate parsing in a different function. This I think may be faster. But, check for yourself.\n",
    "    \n",
    "+ To speed things up consider `headless browser` but, understand the debugging becomes an issue!\n",
    "\n",
    "+ **If you parse a good amount of pages** you will encounter a checkbox that needs to be clicked to show you are not a robot. This occurs to me usually after 15-30 pages of scraping which is not a lot. (I need to figure this out)\n",
    "    + Option 1: try to see if you can pull the information for this button to scrape it directly and click\n",
    "    + Option 2: reset and tinker with the settings of timing out, sleep settings and maybe error handling\n",
    "\n",
    "**`Big Concern: Pagination`**\n",
    "When you need to go from page to page sequentially this is not straight forward. Practice and a lot of reading will aid you. I am not savvy just yet.\n",
    "+ Clickable buttons and learning how to use them and WHEN TO STOP iterating are NOT trivial tasks\n",
    "+ Hacking your way through, such I did for this example but, there is a glaring issue with duplicate entries.\n",
    "+ Finding hidden elements and figuring out how to extract them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa1863",
   "metadata": {},
   "source": [
    "# `Option 1 Find Description Links From Beginning:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "3c392044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Software Engineer\\nJoin an expert team that is breaking records in real-time Big Data performance\\nChange the way the world manipulates and analyzes large quantities of data\\nAddress our customer’s data pain points and delight them with your solutions\\nSpaceCurve is building Big Data analytic solutions focused on spatial, temporal, sensor and graph applications. Targeting mobile, life sciences, oil and gas and government markets. Our unique database technology can power real-time models of reality. We are enabling completely new applications and radical enhancements to existing applications.\\nThe role:\\nOur product is a database purpose-built to parallelize storage and retrieval of multi-dimensional data on clusters of shared-nothing commodity hardware. It automatically shards and re-balances data across the cluster. We’re looking for a Senior Software Engineer with the vision and hands-on skills to enable early adoption as a key person in the core technical team. You will be working on Big Data pipelines to fuse a wide variety of feeds and data sources, including geospatial/geotemporal, vehicle and industrial sensors, social networks, and place and personal data.\\nYour recent experience must be directly with Terabyte class datasets or larger in a clustered environment. You should be adept at implementing the full life cycle of massive datasets including ETL, EDA, cleaning, data analysis and deployment. You should be thoughtful and knowledgeable about algorithm performance and maximizing throughput. You should be very solid with open source and/or commercial technologies relevant in the Big Data processing space.\\nTo be considered for our Senior Software Engineer, you will need:\\n\\n5+ years software development in three or more of Java, Scala, C++, Julia, Python, SQL\\n2+ years of recent experience working with terabyte or larger datasets.\\nDegree in Math, Statistics, CS, a related field or equivalent experience.\\nAbility to conceive elegant software designs and translate them into efficient implementations\\nHands-on, current experience with relevant Big Data technologies such as Hadoop, Spark, Cascading, Kafka, Open Grid Engine, etc.\\nComfortable working in an agile environment\\nAdditionally, our ideal candidate will possess:\\n\\nBroad exposure to Big Data storage and analysis in multiple contexts with deep expertise in at least one.\\nExperience with multiple database technologies (relational, EDW, NoSQL) and HA.\\nExperience with geospatial and/or graph analytic databases.\\nExperience with streaming APIs and SOA products.\\nExperience with real-time analytics (e.g. mobile marketing).\\nA good cultural fit on our team is a professional and results-oriented individual that can initiate and complete tasks under tight deadlines and changing priorities. Flexibility with hours and workload is key!\\nAbout SpaceCurve\\nOur product is revolutionary. Many have said it, but seldom is it true.\\nSpaceCurve is a well-funded startup on our way to changing the economics, nature, usefulness and significance of Big Data across many market segments. The next ten years will bring explosive growth in mobility and location-based services, and increasing volumes of geospatial and sensor data will drive demand for real-time models of reality. SpaceCurve is uniquely positioned at the intersection of the growing geospatial and intelligent-location trends that are creating immense opportunities for the rapid implementation of its technologies.\\nWe are smart, engaged and passionate about what we do. We believe world-class employees should be rewarded as such. Our employees are offered competitive wages, 401K, premium insurance benefits, flexible PTO, early stage stock options and more!\\nApply now or contact us for a confidential discussion!',\n",
       " \"Description:\\nAs a Campfire Data Engineer you will maintain the balance between strategy and execution to provide outstanding service to our clients. Reporting to your team lead and client(s)for a given project, you will operate largely without oversight. We do not hire 'report-monkeys' - we are looking for curious minds who love to explore data, dig for insights, and mine opportunities.\\n\\nWe've been recognized by Seattle Business Magazine as one of 2021's 100 best places to work!\\nRequirements:\\nPartner directly with clients to understand business problem, project goal, and requirements both functional and technical\\nArchitect end-to-end solutions from ingestion, storage, prepping, and modeling to serve client needs\\nBuild scalable data pipelines programmatically using languages such as SQL, Python, or Spark, including extracting data using APIs\\nImplement data structures using data modeling, ETL/ELT processes, and SQL technologies\\nMinimum Qualifications\\n2+ years of work experience with data warehousing, data modeling and building ETL pipelines using Python/C#/.NET\\n2+ years of work experience working with cloud-based technologies such as: Azure, AWS, or Google Cloud Platform\\n1+ years of work experience writing SQL queries across large datasets such as clickstream data (terabytes)\\n1+ years of experience working with data visualization tools such as Power BI, Tableau, or Looker\\nOn-the-job experience with version control systems (e.g., Git) and DevOps best practices\\nPreferred Qualifications\\nConsulting and/or agency experience\\nFamiliarity with digital marketing concepts\\nHands-on experience working with digital media and clickstream/tapstream data\\nExperience with distributed data/ cloud computing tools: Azure, AWS, Map/Reduce, MS Cosmos, Hadoop, Hive, Spark\\nExperience with DAX and MDX (eg: Ranking, date changing, data transformations, relating data)\\nOur Compensation & Benefits\\nCompensation: The base salary pay range for this position is $60,000 to $170,000, dependent on specific level of skills and work & industry experience. Full-time employees are eligible for the annual profit sharing bonus upon 3 months of employment, and may be eligible for discretionary bonuses.\\nBenefits: Full-time employees are eligible for the below:\\nCompetitive Medical/Dental/Vision coverage: premiums for the employee are covered\\nGroup Life, Short- & Long-term Disability coverage: premiums for the employee are covered\\nPTO (Paid Time Off): flexible vacation policy, recommended 15+ days per calendar year\\nPSST (Paid Sick & Safe Time): flexible sick policy, minimum of 7+ days per calendar year\\nHolidays: 11 days per calendar year\\n401(K) match: 100% for the first 1%, then matches 50% up to another 5% (max 3.5% match on 6% contribution)\\nTraining Stipend: $400 per calendar year\\nErgonomics Stipend: $500 within the first year of employment only\",\n",
       " 'Responsibilities\\nTikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.\\n\\nWhy Join Us\\nAt TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.\\n\\nThe team is missioned to ensure the safety of company-level big data products and compliance with local principals and regulations. We are adding privacy features to Apache\\'s big data ecosystem (Spark, Hive Presto), and building world-class data security & privacy framework for big data tech stack. It\\'s an emerging area where many companies and industry are heavily investing. Your work will impact billions of users and bring \"data for good\" social values.\\n\\nResponsibilities:\\nIdentify the privacy risk through product or software development lifecycle and propose actionable solutions based on best practices of data privacy.\\nEstablish procedures, rules and standards for applying privacy technologies to data life-cycles.\\nPartner with infrastructure teams across the world to collaboratively define, manage, and drive cross functional efforts to deliver privacy and security products and implementations.\\nCommunicate regularly with legal, risk control organizations and leadership on status, risks, and business needs.\\nTrack and benchmark the latest domestic and international legal and regulatory requirements, and promote privacy and security gaps in the rectification process continued.\\nRespond to emergency needs of privacy and establish collaboration processes.\\nQualifications\\n2+ years of experience in software engineering or privacy engineering.\\nBachelor degrees or above in a technical field such as Computer Science or equivalent experience.\\nFamiliarity with domestic and international laws and regulations, such as cybersecurity law, GDPR, HIPAA.\\nPreferred Qualifications:\\nExperience making contributions to the security or privacy community (public research, blogging, presentations, etc.)\\nProficiency in SQL/Hive or Data Analytics tools.\\nTikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.\\n\\nTikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to us at usrc@tiktok.com.\\nJob Information\\nThe base salary range for this position in the selected city is $119700 - $210672 annually.\\n\\n\\n\\nCompensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.\\n\\n\\n\\nAt ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:\\n\\n\\n\\nWe cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.\\n\\n\\n\\nOur time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.\\n\\n\\n\\nWe also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.',\n",
       " 'Responsibilities\\nTikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.\\n\\nWhy Join Us\\nAt TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.\\n\\nThe team are missioned to ensure the safety of company-level big data products and compliance with local principals and regulations. We are adding privacy features to Apache\\'s big data ecosystem (Spark, Hive Presto), and building world-class data security & privacy framework for big data tech stack. It\\'s an emerging area where many companies and industry are heavily investing. Your work will impact billions of users and bring \"data for good\" social values.\\n\\nResponsibilities:\\nDrive data warehouse architecture design, modeling and ETL development according to privacy compliance requirements.\\nParticipate in the privacy compliance governance of large-scale, complex data warehouse.\\nDesign and build data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, multi-dimensional analysis)\\nEstablish solid design and best engineering practices.\\nQualifications\\nBS or MS degree in Computer Science, Data Science or related technical field with at least 3 years of working experience.\\nProficient in data warehouse implementation methodology, experienced in working on data warehouse systems.\\nExperience with Big Data technologies(Hadoop, M/R, Hive, Spark, Presto, Flink, Kafka, ClickHouse etc)\\nExperience in performing data analysis, data ingestion and data integration\\nSolid communication and teamwork contribute to multi-functional teams.\\nTikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.\\n\\nTikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to us at usrc@tiktok.com.\\nJob Information\\nThe base salary range for this position in the selected city is $129200 - $194750 annually.\\n\\n\\n\\nCompensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.\\n\\n\\n\\nAt ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:\\n\\n\\n\\nWe cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.\\n\\n\\n\\nOur time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.\\n\\n\\n\\nWe also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.',\n",
       " 'Education and Experience:\\nBachelor’s Degree or a combination of technical training, certifications, and experience\\nMSCS or other systems related certifications or specialty experience\\n4+ Years of experience\\nCisco CCNA or better with specialties in Voice and Security\\nSecurity+ CE (or appropriate DoDM 8570 Baseline Certification)\\nIAT Level II certification is required before start\\n\\nResponsibilities:\\nImplements system solutions\\nInstalls, configures, operates, & maintains a variety of network & tele-communications systems equipment & architectures mostly packetized environments & focused on directory architecture,\\n\\nKnowledge and Skills:\\nExcellent verbal and written communication skills\\nNetwork operating systems\\nLAN/WAN, & security.\\nTCP/IPv4/6, Ethernet, ISDN/BRI/PRI, and various other communications and network protocols\\nTechnical Knowledge\\nVLANs, VPN, data encryption, network management, information systems/network security, routers, switches, TCP accelerators\\nCollaborative environments, convergence (i.e. MS Windows OS and NOS, Unix, Linux, directory services, NAS and SAN and Tape and Backup, Proxy, Firewalls, VP, IDS, IPS, etc.)\\nCisco Routers and Switches\\nClearance/Citizenship:\\nSecret\\nMust be US Citizen\\n\\nTravel Requirements:\\n\\nThis position will involve less than 10% travel\\n\\nLocation: Joint Base Lewis McChord, Washington',\n",
       " 'Company Introduction\\nOneSource Regulatory Technology hosts a number of innovative solutions to enhance job performance in the Pharmaceutical space. OSR Technology is looking for an experienced and dedicated data engineer to join our product solutions team!\\n\\nJob Description\\nOneSource Regulatory is trying to identify a full-time contractor with at least 4+ years of experience to assist us with ongoing R&D projects.\\nWe are looking for a data engineer to pull data from various sources and do all the necessary steps to clean, normalize, possibly annotate, and finally load the data into databases. The candidate should be able to develop and implement a strategy for testing the data integrity of the collected data. This role requires extreme attention to detail to ensure data quality is top priority.\\n\\nResponsibilities\\nWell versed in parsing and synthesizing of XML and/or JSON documents.\\nCurating of data that can involve some intermediate to advanced web scraping. (data may need to be fetched via SFTP, FTP, Wget, Curl, REST APIs, GraphQL queries from spots on the Internet)\\nProficiency with Linux command line and various simple tools, such as grep, wc, sed, awk, find, ls, cat, piped commands and possibly some very light Bash shell scripting, setting up crontab schedules and programs\\nMust have basic knowledge of SQL with the following databases: PostGres, MySQL, Google BigQuery\\nMust have basic knowledge of No-SQL database knowledge such as MongoDB or similar\\nFamiliarity with basic Cloud technology such as storage buckets, cloud serverless functions\\nMust have experience extracting text and images from PDF files\\nKnowledge of Puppeteer or other automatable web client technologies\\nUnderstanding JavaScript, HTML/CSS and HTTP methods (for understanding page structure for web scraping)\\n\\nSkills\\nSolid experience with Python and Python Libraries such as Pandas, requests, etc\\nSkill set should match up with required responsibilities listed above\\nStrong English skills (e.g. grammatical analysis and rhetorical structure)\\nTeam Player\\nGreat communication skills\\n\\nBonus Skills\\nExperience within the Pharmaceutical Space\\nAbility to expose data via C# NETCore and/or GraphQL\\nGoogle Cloud Platform (Cloud Buckets, Google Cloud Functions (.NET, Python, Node.JS))\\nAbility to parallelize data manipulation and scraping via Python multi-threading, etc.\\nPython BeautifulSoup\\nScrapy\\nDocker (setting up Kubernetes style processing if warranted for data scraping/data ingestion/normalization)\\nMultithreading concepts',\n",
       " 'We are looking for a Data Engineer to help us with implementing new data capabilities at our clients. This is contract, and part-time or full-time, remote, and potentially contract to hire.\\nWhat You’re Good At\\nBuilding Data Pipelines\\nPython\\nAWS\\nBI/DW architectures\\nFlask, Django etc.\\nRelational data bases\\nWorking with other software engineers; Experience working with Data Scientists a plus; Experience with data science tools, ML, etc. a plus.',\n",
       " \"Responsibilities\\nJob Description\\nTikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul, and Tokyo.\\n\\nWhy Join Us\\nAt TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.\\n\\nTikTok Data Access team is responsible for data access control to all online TikTok data, managing data schema in code for attribution and governing, layout foundation for modernized data tracking, deletion, retention, and linkage. We are building an Infrastructure as Code experience for all data models and storage systems and help automate the development and deployment process by providing frameworks and systems based on metadata and schema.\\n\\nWe are looking for motivated individuals interested in complex engineering challenges around one of the most important aspects of TikTok. You will have the opportunity to work closely with a multidisciplinary team of Mobile Engineers, Frontend Engineers, Site Reliability Engineers, Data Engineers, and Data Scientists in a high-impact and fast-paced environment.\\n\\nAs a Senior Software Engineer on our TikTok Data Access team, you will:\\nLead some of critical domains of data access, such Object-Relational Mapping, variable storage adapters and privacy and safety policy and management\\nDesign new massive-scale software systems that demand low latency, high reliability, and resilience against disaster, by applying the concept of Infrastructure as Code and Schema as Code.\\nDevelop systems to handle the next phase of growth TikTok's business and ensure high stability and performance.\\nCollaborate with multiple cross-functional teams to identify new investments, solve critical problems, and deliver high-quality work in rapid product development.\\nQualifications\\nRequirements\\nBS Degree in Computer Science or related major, with at least 5 years of working experience.\\nProficient in at least one OOP language, such as Java, Go, C++, Python, etc.\\nExperience in building backend services for large-scale consumer-facing applications.\\nFamiliar with common open source distributed middleware and components such as MySQL, MongoDB, Redis, and MQ.\\nUnderstanding of design ideas for distributed system and architecture, including but not limited to service-oriented, asynchronous, highly available, scalable, etc.\\nDeep understanding of computer architectures, data structures, and algorithms.\\nGood communication and collaboration skills.\\nQualifications\\nRequirements\\nBS Degree in Computer Science or related major, with at least 5 years of working experience.\\nProficient in at least one OOP language, such as Java, Go, C++, Python, etc.\\nExperience in building backend services for large-scale consumer-facing applications.\\nFamiliar with common open source distributed middleware and components such as MySQL, MongoDB, Redis, and MQ.\\nUnderstanding of design ideas for distributed system and architecture, including but not limited to service-oriented, asynchronous, highly available, scalable, etc.\\nDeep understanding of computer architectures, data structures, and algorithms.\\nGood communication and collaboration skills.\\nTikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.\\n\\nTikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to us at usrc@tiktok.com.\\nJob Information\\nThe base salary range for this position in the selected city is $175750 - $266000 annually.\\n\\n\\n\\nCompensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.\\n\\n\\n\\nAt ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:\\n\\n\\n\\nWe cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.\\n\\n\\n\\nOur time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.\\n\\n\\n\\nWe also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.\",\n",
       " 'About the Role\\nGray is a human-centered digital services company with a mission to transform critical government services using design and technology. We partner with government agencies to deliver digital solutions that are purposeful, trustworthy, and meet the needs of millions of Americans. We\\'re looking for the most tenacious and mission-obsessed team members committed to nurturing a people-first culture and reimagining how the government serves its citizens.\\nOur Engineer - Data Migration will work directly with The U.S. Department of Veterans Affairs and Accenture Federal Services Services to modernize and improve GI Bill claims processing for veterans, service members, and dependents. As a key member of the team, you\\'ll contribute directly to impactful digital services transformation that empowers government agencies and civil servants to better serve the American people by delivering a best-in-class user experience.\\nYou are a team player who knows how to collaborate with many different teams and stakeholders, and prevent technical bottlenecks. You are a self-starter who never stops learning and helps their team perform at its best.\\nAre you passionate about untangling and redesigning government services to better serve Americans? Do you strive to do meaningful work with a company that cares about its people\\'s well-being? In that case, Gray is the right company for you.\\nWhat You\\'ll Do (Primary Responsibilities):\\nPerform database functions across one or more teams or clients, including designing, implementing and maintaining new databases, backup/recovery and configuration management.\\nAdminister, develop, test, or demonstrate databases.\\nDesign, Develop, Test and implement the Data Migration scripts.\\nWhat You\\'ll Bring (Requirements):\\nEducation Requirements: A Bachelor\\'s Degree in computer science, electronics engineering or other engineering or technical discipline is required.\\nYears of experience: 5+ years experience.\\nRequired Skills:\\nGood understanding of AWS Data and storage families.\\n5+ years in Cloud technology, working with AWS Athena, Glue, S3, AWS DMS and AWS SCT\\nPrior experience in migrating data from on premise (Mainframe, Oracle, SQLDB etc.) to cloud platform.\\nExperience in optimizing and troubleshooting ETL processes and Data pipelines.\\nAgile development experience\\nExperience in AWS Aurora (PostgreSQL)\\nExperience in Data Migrations and ETL methodologies.\\nPreferred Skills:\\n2+ years hands on experience in building data pipelines in SQL, Python (preferred)\\nPrevious experience with VA and working on VA legacy systems for Education Service\\nWhat Our Team Values:\\nMission and values-driven - passionate about prioritizing Gray\\'s values and mission to transform how the government serves its citizens.\\nPositive can-do attitude - can navigate challenges and find solutions while being tenacious, optimistic, and results driven.\\nSelf-starter with a bias for action - works well without a lot of direction and thrive on being accountable to discover problems, create goals, and execute plans.\\nResilience - dependable in the face of adversity and handle uncertainty and obstacles with grace and elegance.\\nCollaboration - embrace differing perspectives to make better decisions and collaborate effectively with people of diverse backgrounds and cultures.\\nPassion - strong ability to motivate and inspire people to do their best work.\\nCommunication - exceptional written, verbal, relationship building, and emotional intelligence skills.\\nCuriosity - constant desire to learn and improve.\\nAnalytical thinking - in search of the truth and can dig into data to make reasoned decisions objectively.\\nIntegrity and selflessness - treat people with respect, take a stand yet commit even in disagreement, and are known for your candor and sincerity.\\nCompensation\\n$110,000 - 130,000 Base Salary + Benefits + Growth Potential\\nWhy Gray (Benefits and Perks):\\nGray is an experienced team of dreamers, doers, and change-makers brought together by a shared commitment to doing work that matters, solving big problems, and upholding Gray\\'s mission and values in our daily interactions.\\nWhile our headquarters is in Boulder, CO (recently named the best place to live by U.S. News), we are a remote first company and you\\'re free to work where you work best, anywhere within the US.\\nWe care about the happiness of our people. We offer an industry best benefits package and cultivate an environment of empowerment, autonomy with accountability, and a commitment to a healthy work-life balance. Join our team and help defend our vision to deliver meaningful work and a people-first culture.\\n\"If you want to build a ship, don\\'t drum up the people to gather wood, divide the work, and give orders. Instead, teach them to yearn for the vast and endless sea.\"\\nHere are highlights of our benefits package:\\nCompetitive Compensation - We monitor industry salaries annually and make sure we\\'re paying in the top tier based on skills and experience, for every position at the company. Base salaries are standardized on the Colorado market (our headquarters).\\nRemote-Friendly - We hire the most talented technologists from across the country and are committed to being a remote-first company. We want you to perform at your best, and promise to help you feel comfortable and connected wherever you call home.\\nFlexible Work Schedules - We treat our people like adults and trust you to manage your schedule. We offer flexible hours to align with your work style.\\nUnlimited Vacation - Taking time off to promote health and wellness is crucial to your well being. There\\'s no prescribed vacation or sick day policies. If you\\'re feeling under the weather or need a mental health day, take time to recharge, it\\'s good for you!\\n100% Health Coverage - We pay 100% of your medical, dental, and vision insurance premiums.\\n401k Match - Saving for retirement and investing in your financial future is important. That\\'s why Gray matches 401K contributions up to 6% of your salary.\\nProfessional Development - We want to invest in your growth and development. If you find a class, conference, or opportunity to advance your skill-set, we will help offset the cost up to $2,000.00 per year.\\nWellness Allowance -We want you to do your best work, and we know that your health and happiness are critical to making that happen. We offer up to $50.00 per month reimbursement toward whatever it is that heals you-yoga class, acupuncture-you name it!\\nPublishing and Speaking Opportunities - We encourage you to be thought leaders and share your knowledge and expertise. Let\\'s build a more interconnected, diverse, and prosperous digital services community together.\\nSwag Budget - New hires receive a gift certificate to Gray\\'s curated online store of branded merchandise. We promise it\\'s quality merch you\\'ll enjoy. Take a peek and see for yourself. We\\'re regularly adding new products.\\nTech and Tools Allowance - You choose whatever technical tools you need to work most effectively. Each year, you can expense up to $500 on the tech gear and tools you need. This includes an external monitor, standing desk, 3D printer, and more.\\nMission and Public Good Impact - We are brought together by a shared commitment to do work that matters. You\\'ll work on projects that transform government services, strengthen national defense and are critical to the well-being of millions of Americans.\\nWork-life balance. Whether you need to take a midday run or step out to pick up your kid from childcare, we want to see your best self at Gray - that means helping you lead a healthy life outside of work.\\nOur mission is bold, audacious, and there\\'s a lot on the line. It\\'s a significant career move, and we appreciate the courage and passion that go into considering us. We look forward to hearing from you.\\nWhat You Should Know:\\nFederal contracts require that you be a U.S. Citizen or Green Card holder to be eligible for employment.\\nAll work must be conducted within the U.S.\\nYou may be required to meet additional pre-employment contingencies to the extent required by applicable law, at the time of hire or any time thereafter.\\nEqual Opportunity & Inclusive Workplace. Gray is deeply committed to diversity, equity and inclusion and making our organization a hospital and accessible place for all individuals. Gray is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, ethnicity, national origin, sexual orientation, gender identity or expression, religion, age, pregnancy, disability, work-related injury, covered veteran status, political ideology, marital status, or any other factor that the law protects from employment discrimination.\\nAbout Gray\\nGray is a human-centered digital services company using design and technology to transform government services. We deploy highly-efficient, cross-functional digital service teams to empower government agencies and civil servants to better serve the American people. These multi-disciplinary groups leverage agile software development, DevOps, and human-centered design to deliver mission-critical products with a purpose.\\nFounded by technologists from the White House\\'s U.S. Digital Service (USDS), Gray has experience at the highest levels of government, academia, and the commercial sector. Our executive leadership and advisory board have diverse backgrounds from a wide range of organizations, including Google, Deloitte, The White House, The U.S. Military Academy at West Point, Airbnb, Duke University, and more.\\nOur team members have created and sold tech startups, led COVID 19 front-line operations, served tours of civic service to reimagine government in the digital era, and built some of the most innovative and well-loved technology products on earth. Leveraging our unique blend of government, academia, and commercial expertise, we work closely with our partners to solve their most pressing technical challenges.\\nThe Gray team is brought together by a shared commitment and unconventional approach to untangle and redesign mission-critical government services. Whether we\\'re improving access to Veterans\\' disability benefits, building sensors to save lives in war-torn Syria, or developing secure and equitable products for U.S. Citizenship and Immigration Services (USCIS), we thrive on delivering digital solutions that are purposeful, trustworthy, and meet the needs of millions of people.\\nAt Gray, we\\'ve established a people-first strategy. That\\'s why our culture encourages self-care, professional development, and nurturing a sense of ownership and responsibility. We believe that a happy team and intentional and mindful growth lead to the best outcomes for our partners and our business.',\n",
       " \"Responsibilities\\nAbout TikTok\\nTikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo.\\n\\nWhy Join Us\\nAt TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.\\n\\nAbout USDS\\nAt TikTok, we're committed to a process of continuous innovation and improvement in our user experience and safety controls. We're proud to be able to serve a global community of more than a billion people who use TikTok to creatively express themselves and be entertained, and we're dedicated to giving them a platform that builds opportunity and fosters connection. We also take our responsibility to safeguard our community seriously, both in how we address potentially harmful content and how we protect against unauthorized access to user data.\\n\\nU.S. Data Security (“USDS”) is a standalone department of TikTok in the U.S. This new security-first division was created to bring heightened focus and governance to our data protection policies and content assurance protocols to keep U.S. users safe. Our focus is on providing oversight and protection of the TikTok platform and user data in the U.S., so millions of Americans can continue turning to TikTok to learn something new, earn a living, express themselves creatively, or be entertained. The teams within USDS that deliver on this commitment daily span Trust & Safety, Security & Privacy, Engineering, User & Product Ops, Corporate Functions and more.\\n\\nResponsibilities:\\nBuild machine learning solutions to respond to and mitigate business risks in TikTok products/platforms. Such risks include and are not limited to abusive accounts, fake engagements, spammy redirection, scraping, fraud, etc.\\nImprove modeling infrastructures, labels, features and algorithms towards robustness, automation and generalization, reduce modeling and operational load on risk adversaries and new product/risk ramping-ups.\\nUplevel risk machine learning excellence on privacy/compliance, interpretability, risk perception and analysis.\\nQualifications\\n\\nQualifications:\\nMaster or above degree in computer science, statistics, or other relevant, machine-learning-heavy majors.\\nSolid engineering skills. Proficiency in at least two of: Linux, Hadoop, Hive, Spark, Storm.\\nStrong machine learning background. Proficiency or publications in modern machine learning theories and applications such as deep neural nets, transfer/multi-task learning, reinforcement learning, time series or graph unsupervised learning.\\nAbility to think critically, objectively, rationally. Reason and communicate in result-oriented, data-driven manner. High autonomy.\\nTikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.\\n\\nTikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or an accommodation, please reach out to us at usrc@tiktok.com.\\nJob Information\\nThe base salary range for this position in the selected city is $119700 - $210672 annually.\\n\\n\\n\\nCompensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.\\n\\n\\n\\nAt ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:\\n\\n\\n\\nWe cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.\\n\\n\\n\\nOur time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.\\n\\n\\n\\nWe also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.\",\n",
       " \"Responsibilities\\nTikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul, and Tokyo.\\n\\nWhy Join Us\\nAt TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.\\n\\nThe Business Risk Integrated Control (BRIC) team is missioned to:\\nProtect TikTok users, including and beyond content consumers, creators, advertisers;\\nSecure platform health and community experience authenticity;\\nBuild infrastructures, platforms and technologies, as well as to collaborate with many cross-functional teams and stakeholders.\\nThe BRIC team works to minimize the damage of inauthentic behaviors on TikTok platforms (e.g. TikTok, CapCut, Resso, Lark), covering multiple classical and novel community and business risk areas such as account integrity, engagement authenticity, anti spam, API abuse, growth fraud, live streaming security and financial safety (ads or e-commerce), etc.\\nIn this team you'll have a unique opportunity to have first-hand exposure to the strategy of the company in key security initiatives, especially in building scalable and robust, intelligent and privacy-safe, secure and product-friendly systems and solutions. Our challenges are not some regular day-to-day technical puzzles -- You'll be part of a team that's developing novel solutions to first-seen challenges of a non-stop evolvement of a phenomenal product eco-system. The work needs to be fast, transferrable, while still down to the ground to making quick and solid differences.\\n\\nResponsibilities:\\nBuild machine learning solutions to respond to and mitigate business risks in TikTok products/platforms. Such risks include and are not limited to abusive accounts, fake engagements, spammy redirection, scraping, fraud, etc.\\nImprove modeling infrastructures, labels, features and algorithms towards robustness, automation and generalization, reduce modeling and operational load on risk adversaries and new product/risk ramping-ups.\\nUplevel risk machine learning excellence on privacy/compliance, interpretability, risk perception and analysis.\\nQualifications\\nMaster or above degree in computer science, statistics, or other relevant, machine-learning-heavy majors.\\nAt least 3 YOE\\nSolid engineering skills. Proficiency in at least two of: Linux, Hadoop, Hive, Spark, Storm.\\nStrong machine learning background. Proficiency or publications in modern machine learning theories and applications such as deep neural nets, transfer/multi-task learning, reinforcement learning, time series or graph unsupervised learning.\\nAbility to think critically, objectively, rationally. Reason and communicate in result-oriented, data-driven manner. High autonomy.\\nTikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.\\n\\nTikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or an accommodation, please reach out to us at USRC@tiktok.com.\\nJob Information\\nThe base salary range for this position in the selected city is $175750 - $266000 annually.\\n\\n\\n\\nCompensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.\\n\\n\\n\\nAt ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:\\n\\n\\n\\nWe cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.\\n\\n\\n\\nOur time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.\\n\\n\\n\\nWe also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.\",\n",
       " 'About MAQ Software\\nAs 2021 Microsoft Power BI Partner of the Year, we enable leading companies to accelerate their business intelligence and analytics initiatives. Our solutions enable our clients to improve their operations, reduce costs, increase sales, and build stronger customer relationships.\\nOur clients consistently recognize us for providing architecture and governance frameworks, implementing best practices to optimize reports, and building team capability through training programs. Our innovative tools and 33 certified visuals expand Power BI capabilities to save time for decision makers.\\nAs a premier supplier to Microsoft for two decades, our clients benefit from our extensive insights on the platform and engineering practices. As a Microsoft Partner with 10 Gold competencies, our clients improve their implementations with our breadth and depth of expertise.\\nWith globally integrated teams in Redmond, Washington, and Mumbai, Hyderabad, and NOIDA India, we deliver solutions with increased velocity and tech intensity.\\nInc. magazine has recognized us for sustained growth by listing us on the Inc. 5000 list ten times – a rare honor.\\n\\nEngineering culture\\nWe foster a strong engineering culture with a can-do attitude. All our key managers come from excellent educational backgrounds and have significant experience growing a company and mentoring software engineers. Due to our smaller size, we adopt the latest technologies and computing trends ahead of the larger industry players. As a part of the company’s globally distributed engineering team, our engineers gain exposure to the latest software engineering practices and fast development cycles.\\nOur developers routinely work on challenging technical problems that utilize the latest technologies for fast-paced software delivery.\\n\\nExamples of some of our projects:\\nWe built a supervised machine learning model that forecasts the impact of retail sales on our client’s overall revenue. We collected data from existing customer relationship management (CRM) and sales systems. We created a forecasting model in Azure Databricks using existing and custom linear regression to process the collected data. To reduce forecast runtime and achieve near real-time analysis, we modified the existing R libraries to SparkR. The improved insight helped our client proactively focus on retailers with the highest sales impact.\\nWe built a check-in app for one of our client’s most attended event. A multinational technology company organizes an annual multi-event internal expo attended by thousands of their employees. The manual process of tracking attendance, sending acknowledgments, and receiving feedback was time consuming. To automate the process, we built a check-in app that uses mobile devices’ camera to capture the identification badge of each participant. The captured images are stored in an Azure Blob. An Azure Logic App reads the image content utilizing Optical Character Recognition (OCR) API to update attendance records. After the event, notifications are sent to attendees via Microsoft Teams to complete a feedback survey using a Microsoft Power Automate Bot. The Feedback App reports the survey responses to determine the Customer Satisfaction (CSAT) score of the event.\\nFor another client with high volume data, we developed and implemented a hybrid data processing solution using Azure Stream Analytics and Azure Databricks to reduce data refresh time from 3 hours to less than 30 minutes. We sourced data from the Azure Event Hub, where refreshes originate. Refreshes are captured through stream analytics and the updated data is pushed to Azure Data Lake Storage (ADLS). The data is processed in ADLS, then pushed to Power BI for reporting.\\nTo read about some of our recent projects, visit https://maqsoftware.com/case-studies\\n\\nResponsibilities:\\nAnalyze existing systems (30%)\\nCollect requirement specifications to analyze business processes and determine the exact nature of user’s system requirements, map process flow, discuss with module leaders and core team members to decide on the architecture.\\nAnalyze existing system structures to provide solutions to improve computer systems to use cloud-based systems and services.\\nAnalyze user requirements to match data available to large computer database source systems to implement solutions at reasonable performance and cost.\\nDesign the processing steps and propose new systems based the user’s requirements. Interact with systems analysts/programmers to develop data migration tools, create processes for the new computer system and attend to ad-hoc issues related to day-to-day activities. Work with software developers in the implementation and testing phase.\\n\\nDevelop specifications and workflow (25%)\\nPrepare software specifications, flow charts, and process diagrams for software programmers to follow. Develop and maintain systems documentation such as design specifications, user manuals, technical manuals, descriptions of application operations, and methodology documentation.\\nAnalyze feasibility using commercially available software systems (e.g., Microsoft Azure versus Amazon Web Services) and reporting systems (e.g., Power BI versus Tableau).\\n\\nAnalyze and verify implementation (25%)\\nInteract with systems analysts/programmers to develop data migration tools, create processes for the new computer system and attend to ad-hoc issues related to day-to-day activities.\\nWork with other software developers in the implementation and testing phase.\\nSetup test environment and compare data from multiple sources to verify reports for end users.\\n\\nReview implementation status and reporting (10%)\\nParticipate in technical collaboration meetings and periodical reviews of implementation status.\\nReport weekly task plan to the project management team for implementation of custom software.\\n\\nTraining and certifications (10%)\\nParticipate in technical trainings and complete relevant industry courses and certifications.\\n\\nQualifications:\\nUndergraduate or graduate degree in Computer Science, Information Systems, Electrical Engineering, Applied Computational Math Sciences or related Engineering discipline.\\n\\nBenefits & Salary:\\nAnnual pay range $80,000 - $120,000.\\nPaid time off.\\nComprehensive medical, dental and vision insurance with employee premiums paid in full.\\n401(k) retirement plan with 3% company match and immediate vesting.',\n",
       " \"As a Data Engineer for our Data Platform Engineering team you will join skilled Scala/ Spark engineers and core database developers responsible for developing hosted cloud analytics infrastructure (Apache Spark-based), distributed SQL processing\\nframeworks, proprietary data science platforms, and core database optimization. This team is responsible for building the automated, intelligent, and highly performant query planner and execution engines, RPC calls between data\\nwarehouse clusters, shared secondary cold storage, etc. This includes building new SQL features and customer-facing functionality, developing novel query optimization techniques for industry-leading performance, and building a database\\nsystem that's highly parallel, efficient and fault-tolerant. This is a vital role reporting to exec leadership and senior engineering leadership\\nRequirements\\n\\nResponsibilities:\\nWriting Scala code with tools like Apache Spark + Apache Arrow + Apache Kafka to build a hosted, multi-cluster data warehouse for Web3\\nDeveloping database optimizers, query planners, query and data routing mechanisms, cluster-to-cluster communication, and workload management techniques.\\nScaling up from proof of concept to “cluster scale” (and eventually hundreds of clusters with hundreds of terabytes each), in terms of both infrastructure/architecture and problem structure\\nCodifying best practices for future reuse in the form of accessible, reusable patterns, templates, and code bases to facilitate meta data capturing and management\\nManaging a team of software engineers writing new code to build a bigger, better, faster, more optimized HTAP database (using Apache Spark, Apache Arrow, Kafka, and a wealth of other open source data tools)\\nInteracting with exec team and senior engineering leadership to define, prioritize, and ensure smooth deployments with other operational components\\nHighly engaged with industry trends within analytics domain from a data acquisition processing, engineering, management perspective\\nUnderstand data and analytics use cases across Web3 / blockchains\\nSkills & Qualifications\\nBachelor’s degree in computer science or related technical field. Masters or PhD a plus.\\n6+ years experience engineering software and data platforms / enterprise-scale data warehouses, preferably with knowledge of open source Apache stack (especially Apache Spark, Apache Arrow, Kafka, and others)\\n3+ years experience with Scala and Apache Spark (or Kafka)\\nA track record of recruiting and leading technical teams in a demanding talent market\\nRock solid engineering fundamentals; query planning, optimizing and distributed data warehouse systems experience is preferred but not required\\nNice to have: Knowledge of blockchain indexing, web3 compute paradigms, Proofs and consensus mechanisms... is a strong plus but not required\\nExperience with rapid development cycles in a web-based environment\\nStrong scripting and test automation knowledge\\nNice to have: Passionate about Web3, blockchain, decentralization, and a base understanding of how data/analytics plays into this\",\n",
       " \"Senior data engineer\\nJob Summary and Mission\\nThis position contributes to Starbuck's success by building enterprise data services for analytic solutions. This position is responsible for design, development, testing, and support for data pipelines and data products to enable continuous data processing for data exploration, data preparation, and real-time business analytics.\\nSummary of Key Responsibilities\\nResponsibilities and essential job functions include but are not limited to the following:\\nDemonstrate deep knowledge of the data engineering domain, including non-interactive (batch, distributed) & real-time, highly available data, data pipelines\\nDeep knowledge of data as a concept and the development of domain driven data products.\\nOptimization of data products to service customer personas, Data science, AI/ML and data visualization.\\nKnowledge of semantic data concepts.\\nBuild fault-tolerant, self-healing, adaptive, and highly accurate data computational pipelines\\nProvide consultation and lead the implementation of complex programs\\nDevelop and maintain documentation relating to all assigned systems and projects\\nPerform root cause analysis to identify permanent resolutions to software or business process issues\\nBasic Qualifications\\nBachelor’s degree in computer science, management information systems, or related discipline, or equivalent work experience\\nMUST HAVE Technology skills (7/10 or higher):\\nStrong/expert Spark (PySpark) Using Jupyter Notebooks, Colab or DataBricks\\nHands-on data pipeline development, ingest patterns in Azure\\nOrchestration tools, ADF or Airflow\\nSQL\\nDenormalized Data modeling for big data systems\\nMUST HAVE competencies:\\nCollaborative, able to work remotely, and still be an engaging team member.\\nStrong analytical and design skills.\\nYears\\nArchitect and design large scale high performance distributed systems 7-10\\nSQL Platform 7-10\\nNo-SQL Platform 3+\\nSpark 3+\\nData platform implementation on Azure or AWS 3+\\nCI/CD experience 2+\\nExposure to SOA architecture 2+\\n\\ndiv>\\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\\n\\nWe are committed to creating a diverse and welcoming workplace that includes partners with diverse backgrounds and experiences. We believe that enables us to better meet our mission and values while serving customers throughout our global communities. People of color, women, LGBTQIA+, veterans and persons with disabilities are encouraged to apply.\\n\\nQualified applicants with criminal histories will be considered for employment in a manner consistent with all federal state and local ordinances. Starbucks Corporation is committed to offering reasonable accommodations to job applicants with disabilities. If you need assistance or an accommodation due to a disability, please contact us at applicantaccommodation@starbucks.com.\",\n",
       " 'Basic Requirements:\\nTechnical requirements:\\nUnderstands Data communications Basics (OSI Model)\\nMinimum two years Data network design, implementation or optimization experience with T1, E1, DS3, Frame Relay, ATM, ISDN\\nFamiliarity with the test equipment (e.g. protocol analyzers, ISDN Test set, Inet etc.)\\nCan interpret and post process data either in graphical format (e.g. Mapinfo) or in statistical format\\nCan understand pre and post cut datacom activities\\nCan identify and troubleshoot datacom and IP telephony problems\\nPerform system and acceptance tests to ensure the deliverables meet the project requirements\\nMake technical recommendations (parameter, settings, feature activation)\\nCan collect and monitor network performance statistics\\nMinimum two years data network experience using complex network addressing, interior and exterior gateway routing protocols and network management.\\nTools and Software:\\nFamiliar with T-Bird, Optnet, SunSet, Inet, Ameritec\\nMicrosoft Project\\nProficient in network protocol analyzers\\nMicrosoft windows, Excel, MS Word',\n",
       " 'Senior Software Engineer\\nJoin an expert team that is breaking records in real-time Big Data performance\\nChange the way the world manipulates and analyzes large quantities of data\\nAddress our customer’s data pain points and delight them with your solutions\\nSpaceCurve is building Big Data analytic solutions focused on spatial, temporal, sensor and graph applications. Targeting mobile, life sciences, oil and gas and government markets. Our unique database technology can power real-time models of reality. We are enabling completely new applications and radical enhancements to existing applications.\\nThe role:\\nOur product is a database purpose-built to parallelize storage and retrieval of multi-dimensional data on clusters of shared-nothing commodity hardware. It automatically shards and re-balances data across the cluster. We’re looking for a Senior Software Engineer with the vision and hands-on skills to enable early adoption as a key person in the core technical team. You will be working on Big Data pipelines to fuse a wide variety of feeds and data sources, including geospatial/geotemporal, vehicle and industrial sensors, social networks, and place and personal data.\\nYour recent experience must be directly with Terabyte class datasets or larger in a clustered environment. You should be adept at implementing the full life cycle of massive datasets including ETL, EDA, cleaning, data analysis and deployment. You should be thoughtful and knowledgeable about algorithm performance and maximizing throughput. You should be very solid with open source and/or commercial technologies relevant in the Big Data processing space.\\nTo be considered for our Senior Software Engineer, you will need:\\n\\n5+ years software development in three or more of Java, Scala, C++, Julia, Python, SQL\\n2+ years of recent experience working with terabyte or larger datasets.\\nDegree in Math, Statistics, CS, a related field or equivalent experience.\\nAbility to conceive elegant software designs and translate them into efficient implementations\\nHands-on, current experience with relevant Big Data technologies such as Hadoop, Spark, Cascading, Kafka, Open Grid Engine, etc.\\nComfortable working in an agile environment\\nAdditionally, our ideal candidate will possess:\\n\\nBroad exposure to Big Data storage and analysis in multiple contexts with deep expertise in at least one.\\nExperience with multiple database technologies (relational, EDW, NoSQL) and HA.\\nExperience with geospatial and/or graph analytic databases.\\nExperience with streaming APIs and SOA products.\\nExperience with real-time analytics (e.g. mobile marketing).\\nA good cultural fit on our team is a professional and results-oriented individual that can initiate and complete tasks under tight deadlines and changing priorities. Flexibility with hours and workload is key!\\nAbout SpaceCurve\\nOur product is revolutionary. Many have said it, but seldom is it true.\\nSpaceCurve is a well-funded startup on our way to changing the economics, nature, usefulness and significance of Big Data across many market segments. The next ten years will bring explosive growth in mobility and location-based services, and increasing volumes of geospatial and sensor data will drive demand for real-time models of reality. SpaceCurve is uniquely positioned at the intersection of the growing geospatial and intelligent-location trends that are creating immense opportunities for the rapid implementation of its technologies.\\nWe are smart, engaged and passionate about what we do. We believe world-class employees should be rewarded as such. Our employees are offered competitive wages, 401K, premium insurance benefits, flexible PTO, early stage stock options and more!\\nApply now or contact us for a confidential discussion!']"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()),\n",
    "                         options=option)\n",
    "sleep(randint(2, 6))\n",
    "\n",
    "\n",
    "for i in range(0,max_iter_pgs):\n",
    "    driver.get(paginaton_url.format(job_,location,i*10))\n",
    "    \n",
    "    sleep(randint(2, 4))\n",
    "\n",
    "    job_page = driver.find_element(By.ID,\"mosaic-jobResults\")\n",
    "    jobs = job_page.find_elements(By.CLASS_NAME,\"job_seen_beacon\") # return a list\n",
    "\n",
    "    for jj in jobs:\n",
    "        job_title = jj.find_element(By.CLASS_NAME,\"jobTitle\")\n",
    "\n",
    "                \n",
    "        # Click the job element to get the description\n",
    "        job_title.click()\n",
    "        \n",
    "        # Help to load page so we can find and extract data\n",
    "        sleep(randint(3, 5))\n",
    "\n",
    "        try: \n",
    "            job_description_list.append(driver.find_element(By.ID,\"jobDescriptionText\").text)\n",
    "            \n",
    "        except: \n",
    "            \n",
    "            job_description_list.append(None)\n",
    "driver.quit()\n",
    "# job_description_list[-17:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "951b96c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_description_list_02=[]\n",
    "descr_link_lst=[]\n",
    "for descr_link in range(len(job_lst)):\n",
    "    descr_link_lst.append(job_lst[descr_link][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2a699f",
   "metadata": {},
   "source": [
    "# `Option 2: call links from list, iterate links directly`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "b4f18c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1201.497257232666\n"
     ]
    }
   ],
   "source": [
    "# headless browser\n",
    "# possible wait function for page to load\n",
    "\n",
    "# import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "for link in descr_link_lst:\n",
    "    option_= webdriver.ChromeOptions()\n",
    "\n",
    "# Going undercover:\n",
    "    option_.add_argument(\"--incognito\")\n",
    "    \n",
    "    option_.add_argument(\"--headless=new\")\n",
    "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()),\n",
    "                         options=option_)\n",
    "    driver.get(link)\n",
    "#     job_page = driver.find_element(By.ID,\"mosaic-jobResults\")\n",
    "#     jobs = job_page.find_elements(By.CLASS_NAME,\"job_seen_beacon\") # return a list\n",
    "    sleep(randint(2, 5))\n",
    "    try: \n",
    "        job_description_list_02.append(driver.find_element(By.ID,\"jobDescriptionText\").text)\n",
    "#         print(driver.find_element(By.ID,\"jobDescriptionText\").text)   \n",
    "    except: \n",
    "            \n",
    "        job_description_list_02.append(None)\n",
    "    driver.quit()\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "b3858ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Senior Software Engineer\\nJoin an expert team that is breaking records in real-time Big Data performance\\nChange the way the world manipulates and analyzes large quantities of data\\nAddress our customer’s data pain points and delight them with your solutions\\nSpaceCurve is building Big Data analytic solutions focused on spatial, temporal, sensor and graph applications. Targeting mobile, life sciences, oil and gas and government markets. Our unique database technology can power real-time models of reality. We are enabling completely new applications and radical enhancements to existing applications.\\nThe role:\\nOur product is a database purpose-built to parallelize storage and retrieval of multi-dimensional data on clusters of shared-nothing commodity hardware. It automatically shards and re-balances data across the cluster. We’re looking for a Senior Software Engineer with the vision and hands-on skills to enable early adoption as a key person in the core technical team. You will be working on Big Data pipelines to fuse a wide variety of feeds and data sources, including geospatial/geotemporal, vehicle and industrial sensors, social networks, and place and personal data.\\nYour recent experience must be directly with Terabyte class datasets or larger in a clustered environment. You should be adept at implementing the full life cycle of massive datasets including ETL, EDA, cleaning, data analysis and deployment. You should be thoughtful and knowledgeable about algorithm performance and maximizing throughput. You should be very solid with open source and/or commercial technologies relevant in the Big Data processing space.\\nTo be considered for our Senior Software Engineer, you will need:\\n\\n5+ years software development in three or more of Java, Scala, C++, Julia, Python, SQL\\n2+ years of recent experience working with terabyte or larger datasets.\\nDegree in Math, Statistics, CS, a related field or equivalent experience.\\nAbility to conceive elegant software designs and translate them into efficient implementations\\nHands-on, current experience with relevant Big Data technologies such as Hadoop, Spark, Cascading, Kafka, Open Grid Engine, etc.\\nComfortable working in an agile environment\\nAdditionally, our ideal candidate will possess:\\n\\nBroad exposure to Big Data storage and analysis in multiple contexts with deep expertise in at least one.\\nExperience with multiple database technologies (relational, EDW, NoSQL) and HA.\\nExperience with geospatial and/or graph analytic databases.\\nExperience with streaming APIs and SOA products.\\nExperience with real-time analytics (e.g. mobile marketing).\\nA good cultural fit on our team is a professional and results-oriented individual that can initiate and complete tasks under tight deadlines and changing priorities. Flexibility with hours and workload is key!\\nAbout SpaceCurve\\nOur product is revolutionary. Many have said it, but seldom is it true.\\nSpaceCurve is a well-funded startup on our way to changing the economics, nature, usefulness and significance of Big Data across many market segments. The next ten years will bring explosive growth in mobility and location-based services, and increasing volumes of geospatial and sensor data will drive demand for real-time models of reality. SpaceCurve is uniquely positioned at the intersection of the growing geospatial and intelligent-location trends that are creating immense opportunities for the rapid implementation of its technologies.\\nWe are smart, engaged and passionate about what we do. We believe world-class employees should be rewarded as such. Our employees are offered competitive wages, 401K, premium insurance benefits, flexible PTO, early stage stock options and more!\\nApply now or contact us for a confidential discussion!'"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Description from 2nd to last entry as illustrate\n",
    "job_description_list_02[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "60eb66cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "575.802490234375\n"
     ]
    }
   ],
   "source": [
    "# Trying to do Threading for speed up:\n",
    "\n",
    "# import threading\n",
    "# from selenium import webdriver\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "class ScrapeThread(threading.Thread):\n",
    "    def __init__(self, url):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.url = url\n",
    "\n",
    "threads = []\n",
    "for url in descr_link_lst:\n",
    "    option_= webdriver.ChromeOptions()\n",
    "\n",
    "# Going undercover:\n",
    "    option_.add_argument(\"--incognito\")\n",
    "    \n",
    "    option_.add_argument(\"--headless=new\")\n",
    "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()),\n",
    "                         options=option_)\n",
    "    driver.get(url)\n",
    "    t = ScrapeThread(url)\n",
    "    t.start()\n",
    "    \n",
    "    try: \n",
    "        threads.append(driver.find_element(By.ID,\"jobDescriptionText\").text)\n",
    " \n",
    "    except: \n",
    "        threads.append(None)\n",
    "        \n",
    "driver.quit()\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878171e5",
   "metadata": {},
   "source": [
    "# `Why I cannot use Beautiful Soup ANYMORE.. Let's talk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "11364bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for url_link in descr_link_lst:\n",
    "# job_descr_txt=[]    \n",
    "# # headers=headers\n",
    "# url_1='https://www.indeed.com/jobs?q={}&l={}&radius=35&filter=0&sort=date'\n",
    "# response = requests.get(url_1.format('data+engineer','denver'))\n",
    "# # ,headers=headers)\n",
    "# print(response)\n",
    "# html_ = response.text\n",
    "# # print(html_)\n",
    "# soup_ = BeautifulSoup(html_, 'html.parser')\n",
    "# print(soup_.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "6c683717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Engineer- W2 and onsite-(No C2C Candidates)\n",
      "Estimated $101K - $128K a year\n",
      "Data Engineer, Workforce Solutions, Ops HR - WW Ops Ppl Prod-Tech\n",
      "From $123,700 a year\n",
      "Data and Analytics Engineer - Senior Associate\n",
      "Estimated $114K - $145K a year\n",
      "Data Center Structural Engineer\n",
      "From $93,500 a year\n",
      "Senior Data Engineer (US Remote)\n",
      "Estimated $125K - $158K a year\n",
      "Data Engineer\n",
      "None\n",
      "Artica - Senior Data Applied Science Engineer (Seattle, WA) - Direct Hire [Hybrid]\n",
      "$180,000 - $200,000 a year\n",
      "Data Engineer\n",
      "$140,000 - $190,000 a year\n",
      "Staff Software Engineer - Data Science\n",
      "$149,240 - $200,200 a year\n",
      "Staff Software Engineer - Data Integration\n",
      "$149,240 - $200,200 a year\n",
      "Principal Software Engineer (Data), Industry Solutions Engineering\n",
      "$133,600 - $256,800 a year\n",
      "Software Engineer, Data Platform\n",
      "Estimated $137K - $174K a year\n",
      "Software Engineer, Data Platform\n",
      "None\n",
      "Senior Backend Engineer - Data\n",
      "$140,000 - $215,000 a year\n",
      "Customer Engineer, Data Analytics, Google Cloud\n",
      "None\n",
      "Staff Full Stack Engineer - Data\n",
      "$175,000 - $225,000 a year\n",
      "Distributed Data Systems - Staff Software Engineer\n",
      "$182,400 - $247,000 a year\n",
      "Senior Software Engineer - Distributed Data Systems\n",
      "$157,700 - $213,800 a year\n",
      "Principal Software Engineer, Data (Starshield)\n",
      "$200,000 - $270,000 a year\n",
      "Senior Data Engineer\n",
      "Estimated $133K - $168K a year\n",
      "Data Engineer, Data Platform - US Tech Services Team\n",
      "$177,688 - $341,734 a year\n",
      "Senior Data Engineer\n",
      "$187,000 - $190,300 a year\n",
      "Data Center Operations Engineer (Kirkland, WA)\n",
      "$45 - $51 an hour\n",
      "Solutions Engineer - Data & Machine Learning\n",
      "$115,000 - $150,000 a year\n",
      "Site Reliability Engineer, Data Platform-TikTok-US-Tech Services\n",
      "$129,960 - $246,240 a year\n",
      "Senior Software Engineer, TikTok Protected Data Infrastructure\n",
      "$175,750 - $266,000 a year\n",
      "Tech Lead Software Engineer, TikTok Protected Data Infrastructure\n",
      "$199,500 - $340,100 a year\n",
      "Sr. Data Engineer\n",
      "$100,531 - $138,230 a year\n",
      "Lead Software Engineer; Cloud and Big Data\n",
      "$137,750 - $200,000 a year\n",
      "Senior Data Engineer - Data Warehouse - Hybrid In Seattle WA or Frisco TX\n",
      "$115,300 - $172,800 a year\n",
      "Senior Data Engineer, Kuiper Business Development\n",
      "From $123,700 a year\n",
      "SLD Senior Avionics Command and Data Handling Responsible Engineer - Lunar Transportation\n",
      "$125,400 - $183,920 a year\n",
      "mgr engineer - Data Engineering\n",
      "None\n",
      "Data Engineer\n",
      "Estimated $113K - $143K a year\n",
      "Data Engineer (Starlink)\n",
      "$120,000 - $145,000 a year\n",
      "Senior Data Engineer\n",
      "$125,000 - $155,000 a year\n",
      "Data Acquisition Software Engineer\n",
      "$112,000 - $215,000 a year\n",
      "Senior Business Intelligence Engineer - Data Center Learning, Data Center Learning\n",
      "From $104,300 a year\n",
      "Senior Data Engineer\n",
      "Estimated $137K - $173K a year\n",
      "Data Engineer, Ops\n",
      "$95,000 - $130,000 a year\n",
      "Data Engineer\n",
      "None\n",
      "Data Engineer, Product Analytics\n",
      "$165,000 - $232,000 a year\n",
      "Senior Data Engineer\n",
      "None\n",
      "Sr. Data and Storage Engineer\n",
      "$97,993 - $146,989 a year\n",
      "Staff Data Engineer\n",
      "$143,400 - $175,300 a year\n"
     ]
    }
   ],
   "source": [
    "# Short Version to show illustration:\n",
    "\n",
    "paginaton_url_ = 'https://www.indeed.com/jobs?q={}&l={}&sort=date&start={}'\n",
    "\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()),\n",
    "                         options=option)\n",
    "p_=[]\n",
    "salary_list_=[]\n",
    "for i in range(0,3):\n",
    "    driver.get(paginaton_url_.format(job_,location,i*10))\n",
    "    sleep(randint(2, 3))\n",
    "    \n",
    "    job_page = driver.find_element(By.ID,\"mosaic-jobResults\")\n",
    "    jobs = job_page.find_elements(By.CLASS_NAME,\"job_seen_beacon\") # return a list\n",
    "    \n",
    "    for jj in jobs:\n",
    "        job_title = jj.find_element(By.CLASS_NAME,\"jobTitle\")\n",
    "        print(job_title.text)\n",
    "        p_.append(job_title.text)\n",
    "#         sleep(randint(3, 5))\n",
    "        try:\n",
    "            salary_list_.append(jj.find_element(By.CLASS_NAME,\"salary-snippet-container\").text)\n",
    "            print(jj.find_element(By.CLASS_NAME,\"salary-snippet-container\").text)\n",
    "\n",
    "        except: \n",
    "            try: \n",
    "                salary_list.append(jj.find_element(By.CLASS_NAME,\"estimated-salary\").text)\n",
    "                print(jj.find_element(By.CLASS_NAME,\"estimated-salary\").text)\n",
    "            except:\n",
    "                print('None')\n",
    "                \n",
    "driver.quit()\n",
    "\n",
    "# //*[@id=\"challenge-stage\"]/div/label/input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7521a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df and store data\n",
    "\n",
    "\n",
    "# duplicate entries remove!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5c045340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "28b6cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider NLP\n",
    "\n",
    "\n",
    "# class ScrapeThread(threading.Thread):\n",
    "#     def __init__(self, url):\n",
    "#         threading.Thread.__init__(self)\n",
    "#         self.url = url\n",
    "\n",
    "        \n",
    "        \n",
    "# multi-thread or asynio\n",
    "# explicit wait with Ec.wait read this and above explainations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831d748",
   "metadata": {},
   "source": [
    "# `Future improvements for this work:`\n",
    "\n",
    "+ Speed up: use asyncio and also look at threading to explain differences\n",
    "+ clean up data, put into DF and do some plotting\n",
    "+ consider more than one job type after speed up\n",
    "+ look into explicit wait times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e00647",
   "metadata": {},
   "source": [
    "# Like, Share & <font color=red>SUB</font>scribe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebeef3e",
   "metadata": {},
   "source": [
    "# `Citations & Help:`\n",
    "\n",
    "# ◔̯◔\n",
    "\n",
    "https://pypi.org/project/webdriver-manager/\n",
    "\n",
    "https://www.blog.datahut.co/post/scrape-indeed-using-selenium-and-beautifulsoup\n",
    "\n",
    "https://github.com/henrionantony/Dynamic-Web-Scraping-using-Python-and-Selenium/blob/master/indeed.py\n",
    "\n",
    "https://www.specrom.com/blog/web-scraping-job-postings-on-indeed-using-python/\n",
    "\n",
    "https://www.scrapingdog.com/blog/scrape-indeed-using-python/ (bs4 as of Feb 13, 2023)\n",
    "\n",
    "https://selenium-python.readthedocs.io/locating-elements.html#locating-elements\n",
    "\n",
    "https://stackoverflow.com/questions/50865088/how-to-get-string-dump-of-lxml-element\n",
    "\n",
    "https://selenium-python.readthedocs.io/navigating.html\n",
    "\n",
    "https://towardsdatascience.com/web-scraping-job-postings-from-indeed-com-using-selenium-5ae58d155daf (2020 version)\n",
    "\n",
    "https://www.pycodemates.com/2022/01/Indeed-jobs-scraping-with-python-bs4-selenium-and-pandas.html\n",
    "\n",
    "https://medium.com/forcodesake/how-to-build-a-scraping-tool-for-indeed-in-8-minutes-data-science-csv-selenium-beautifulsoup-python-95fcca4b9719 (Good Read & Adapted Code)\n",
    "\n",
    "https://www.tutorialspoint.com/how-to-open-browser-window-in-incognito-private-mode-using-python-selenium-webdriver\n",
    "\n",
    "https://www.selenium.dev/selenium/docs/api/py/webdriver/selenium.webdriver.common.keys.html\n",
    "\n",
    "https://pythonbasics.org/selenium-wait-for-page-to-load/\n",
    "\n",
    "https://www.seleniumeasy.com/selenium-tutorials/selenium-headless-browser-execution\n",
    "\n",
    "https://www.browserstack.com/guide/expectedconditions-in-selenium\n",
    "\n",
    "https://www.testim.io/blog/xpath-vs-css-selector-difference-choose/\n",
    "\n",
    "https://www.w3.org/TR/REC-DOM-Level-1/introduction.html\n",
    "\n",
    "https://github.com/diego-florez/Selenium-Web-Scraping/blob/master/indeed.py (Indeed scrape Selenium 2020) error Handling also\n",
    "\n",
    "https://www.testim.io/blog/selenium-click-button/\n",
    "\n",
    "https://scrapfly.io/blog/how-to-scrape-indeedcom/\n",
    "\n",
    "https://goh.physics.ucdavis.edu/datascience/webscraping/webscraping.html\n",
    "\n",
    "https://levelup.gitconnected.com/efficiently-scraping-multiple-pages-of-data-a-guide-to-handling-pagination-with-selenium-and-3ed93857f596\n",
    "\n",
    "https://github.com/israel-dryer/Indeed-Job-Scraper/blob/master/indeed-job-scraper-selenium.ipynb\n",
    "\n",
    "https://www.zenrows.com/blog/headless-browser-python#switch-to-python-selenium-headless-mode\n",
    "\n",
    "https://python.plainenglish.io/pagination-techniques-to-scrape-data-from-any-website-in-python-779cd32bd514\n",
    "\n",
    "https://www.selenium.dev/blog/2023/headless-is-going-away/ (2023 article)\n",
    "\n",
    "https://www.zenrows.com/blog/bypass-cloudflare-python (cloudflare bot blocking 403 error)\n",
    "\n",
    "`Code Optimizing with Asynio, multi-threading and multi-processing:`\n",
    "\n",
    "https://www.geeksforgeeks.org/multithreading-or-multiprocessing-with-python-and-selenium/\n",
    "\n",
    "https://www.youtube.com/watch?v=-hw3AaxX5B4\n",
    "\n",
    "https://webnus.net/how-to-speed-up-selenium-automated-tests-in-2022/ (selenium speed up ideas)\n",
    "\n",
    "https://medium.com/@PhysicistMarianna/scrape-job-postings-data-from-indeed-com-with-python-b4f31340ef5f (bs4 help maybe)\n",
    "\n",
    "https://github.com/Ram-95/Indeed_Job_Scraper/blob/master/Indeed_Job_Scraper.py (bs4 idea as well)\n",
    "\n",
    "https://www.youtube.com/watch?v=HOS5Hix--bE\n",
    "\n",
    "https://stackoverflow.com/questions/75849391/failed-to-fetch-the-job-titles-from-indeed-using-the-requests-module (cloudscraper idea)\n",
    "\n",
    "https://www.geeksforgeeks.org/multithreading-python-set-1/ (multi-threading ex.)\n",
    "\n",
    "https://testdriven.io/blog/building-a-concurrent-web-scraper-with-python-and-selenium/ (come back to this! good write up with code...)\n",
    "\n",
    "https://medium.com/analytics-vidhya/asynchronous-web-scraping-101-fetching-multiple-urls-using-arsenic-ec2c2404ecb4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9aeda",
   "metadata": {},
   "source": [
    "# Notes for this project:\n",
    "\n",
    "+ Filling in forms:\n",
    "+ click buttons\n",
    "+ possible human detection stuff\n",
    "\n",
    "**`Xpath vs CSS selectors for retreiving data`**\n",
    "\n",
    "+ `Xpath:` bidirectional (can go from parent to child and reverse) traversal\n",
    "    + slower retrevial speed\n",
    "    + text functions supported\n",
    "    + pay attention to relative '//' and absolute path '/' notations\n",
    "    + Think of a tree like structure to breakdown\n",
    "+ `CSS:` directional (parent to child only)\n",
    "\n",
    "`------------------------`\n",
    "\n",
    "**`Xpath`**\n",
    "+ *`Xpath`* stands for `XML Path` which is a query language used to find the path of an element in XML documents\n",
    "+ Essentially you are navigating a `DOM` \n",
    "+ More flexible than using `CSS`\n",
    "    + If you don't know the name of an element you can use `contains` as your key word which is great!\n",
    " \n",
    "**`CSS`**\n",
    "+ Most often the HTML will be styled in a cascading format and identifying elements will come from the `Class` they fall within\n",
    "+ They are used to select various elements within a `DOM`\n",
    "    + **`Simple selectors:`** such as finding a `Class` or `ID`\n",
    "    + **`Attribute selectors:`** \n",
    "    + **`Pseudo selectors:`** such as hover boxes or check boxes as examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
