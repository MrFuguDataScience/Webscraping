{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a55bed64",
   "metadata": {},
   "source": [
    "# `Selenium Webscraping Indeed Job Postings - July 2023`\n",
    "\n",
    "# <font color=red>Mr Fugu Data Science</font>\n",
    "\n",
    "# (◕‿◕✿)\n",
    "\n",
    "# `Purpose & Outcome:`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf01d1",
   "metadata": {},
   "source": [
    "# `What is Selenium and how is it used?`\n",
    "\n",
    "+ When you need to do unit testing, automation or assistance when webscraping this is a tool to aid you.\n",
    "    + Great for clicking buttons\n",
    "    + drop-down menus\n",
    "    + acting/emulating human interactions on a webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f45f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if you have never used these: unblock the lines below to install if needed\n",
    "\n",
    "# !pip install webdriver-manager\n",
    "# !pip3 install lxml\n",
    "# !pip3 install selenium\n",
    "# !pip3 install webdriver_manager\n",
    "# !pip install --upgrade pip\n",
    "# !pip install -U selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d754db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- import necessary modules -------\n",
    "\n",
    "# For webscraping\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Parsing and creating xml data\n",
    "from lxml import etree as et\n",
    "\n",
    "# Store data as a csv file written out\n",
    "from csv import writer\n",
    "\n",
    "# In general to use with timing our function calls to Indeed\n",
    "import time\n",
    "\n",
    "# Assist with creating incremental timing for our scraping to seem more human\n",
    "from time import sleep\n",
    "\n",
    "# Dataframe stuff\n",
    "import pandas as pd\n",
    "\n",
    "# Random integer for more realistic timing for clicks, buttons and searches during scraping\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bee43e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "\n",
    "# Check version I am running\n",
    "selenium.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba65a234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selenium 4:\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f41e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows searchs similar to beautiful soup: find_all\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Try to establish wait times for the page to load\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "# Wait for specific condition based on defined task: web elements, boolean are examples\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Used for keyboard movements, up/down, left/right,delete, etc\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# Locate elements on page and throw error if they do not exist\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0c820c",
   "metadata": {},
   "source": [
    "# `Consider Headless Browser: speed up & use less resources:`\n",
    "\n",
    "There are some condiserations though:\n",
    "\n",
    "+ Some browsers create issues\n",
    "+ debugging can be tricky\n",
    "+ you may have limited plugin usage or support\n",
    "+ you are not able to see visually how the website or application are working \n",
    "\n",
    "# `from selenium.webdriver.common.by import By`\n",
    "\n",
    "Think of this as being similar to using `Beautiful Soup and find_all`\n",
    "+ when used it allows you to find something within an HTML document, if it fails you raise the exception: `NoSuchElementException`\n",
    "+ **`Becareful when using BY`** because if this is not a static page then any attrubutes you are searching can become an error in the future when it fails.\n",
    "    + For example if you are searching by `Class` this can create issues later vs using\n",
    "        + This is because it is a `CSS` selector and can change overtime since it is an attribute\n",
    "    + `ID` which may make your code more robust! This CAN be a unique identifier that may help you instead\n",
    "\n",
    "# `NoSuchElementException`\n",
    "\n",
    "This is useful to locate elements within a page while loading and try to handle exceptions.\n",
    "+ During `AJAX` calls you may have issues if the application was build using `React, VUE, Angular` and require different use cases to make the above checks. [article to explain](https://reflect.run/articles/everything-you-need-to-know-about-nosuchelementexception-in-selenium/) and you can consider polling.\n",
    "\n",
    "`--------------------------------`\n",
    "\n",
    "# `Other Common Errors:`\n",
    "\n",
    "+ **`InvalidSelectorException`**\n",
    "\n",
    "+ **`ElementNotInteractableException`**\n",
    "\n",
    "+ **`TimeoutException`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d6c62cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "option= webdriver.ChromeOptions()\n",
    "\n",
    "# Going undercover:\n",
    "option.add_argument(\"--incognito\")\n",
    "\n",
    "\n",
    "# # Consider this if the application works and you know how it works for speed ups and rendering!\n",
    "\n",
    "# option.add_argument('--headless==new')\n",
    "\n",
    "\n",
    "\n",
    "# driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "# # chromedriver = r'chromedriver.exe'\n",
    "# browser = webdriver.Chrome(driver,options=option)\n",
    "# browser.get('indeed.com')\n",
    "# driver.get(\"https://www.indeed.com/q-USA-jobs.html?vjk=823cd7ee3c203ac3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9562812c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae3a9129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define job and location search keywords\n",
    "job_search_keyword = ['Data+Scientist', 'Business+Analyst', 'Data+Engineer', \n",
    "                      'Python+Developer', 'Full+Stack Developer', 'Machine+Learning+Engineer']\n",
    "\n",
    "# Define Locations of Interest\n",
    "location_search_keyword = ['New+York', 'California', 'Los+Angeles']\n",
    "\n",
    "# Define base and pagination URL's\n",
    "base_url = 'https://www.indeed.com'\n",
    "\n",
    "# Finding location, position of interest and starting page\n",
    "paginaton_url = \"https://www.indeed.com/jobs?q={}&l={}&radius=35&start={}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30276a3f",
   "metadata": {},
   "source": [
    "# Things to consider:\n",
    "\n",
    "+ Wait for page to load before we start running tasks\n",
    "+ make sure what we are looking for is actually there\n",
    "    + It can be absent\n",
    "    + hidden in DOM, iframe or similar\n",
    "+ timing our calls to remain more like an average user\n",
    "+ Exception handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b49ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a34e608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a53efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fecf1ed3",
   "metadata": {},
   "source": [
    "# `Here is a side note:`\n",
    "\n",
    "\n",
    "+ This gives me an error because it was code from the past version:\n",
    "\n",
    "`driver = webdriver.Chrome(ChromeDriverManager().install())`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a548150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chrome Webdriver using Chrome Driver Manager\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()),\n",
    "                         options=option)\n",
    "\n",
    "sleep(randint(3, 11))\n",
    "# driver.implicitly_wait(.72)\n",
    "\n",
    "# Open initial URL, and willl wait till its fully loaded.\n",
    "driver.get(\"https://www.indeed.com/q-USA-jobs.html?vjk=823cd7ee3c203ac3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd52f0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider a few options:\n",
    "\n",
    "# 1.) Try to use incognito -----------(done)\n",
    "# 2.) Maybe I should use random int for sleep\n",
    "# 3.) What to do when I have the human click button for pop up\n",
    "# 4.) verify if the \"+\" symbols are needed look at formatting ----------(done)\n",
    "# 5.) check if the formatting to parse is the same or not for div tags, etc\n",
    "# 6.) do I need to use headless browser?\n",
    "# 7.) locating elements using the BY package, similar to beautiful soup find_all\n",
    "# 8.) errors with NoSuchElementException\n",
    "# 9.) try to identify code that doesn't change over time\n",
    "# 10.) Xpath to find buttons to go page by page and contain arrows forward/backward with try.except"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9aeda",
   "metadata": {},
   "source": [
    "# Notes for this project:\n",
    "\n",
    "+ Filling in forms:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9cef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.indeed.com/q-USA-jobs.html?vjk=823cd7ee3c203ac3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86595dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get DOM from given URL\n",
    "def get_dom(url):\n",
    "    driver.get(url)\n",
    "    page_content = driver.page_source\n",
    "    product_soup = BeautifulSoup(page_content, 'html.parser')\n",
    "    dom = et.HTML(str(product_soup))\n",
    "    return dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b2f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in get_dom(url):\n",
    "    print(et.tostring(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f416b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to extract job link\n",
    "def get_job_link(job):\n",
    "    try:\n",
    "        job_link = job.xpath('./descendant::h2/a/@href')[0]\n",
    "    except Exception as e:\n",
    "        job_link = 'Not available'\n",
    "    return job_link\n",
    "\n",
    "\n",
    "# functions to extract job title\n",
    "def get_job_title(job):\n",
    "    try:\n",
    "        job_title = job.xpath('./descendant::h2/a/span/text()')[0]\n",
    "    except Exception as e:\n",
    "        job_title = 'Not available'\n",
    "    return job_title\n",
    "\n",
    "\n",
    "# functions to extract the company name\n",
    "def get_company_name(job):\n",
    "    try:\n",
    "        company_name = job.xpath('./descendant::span[@class=\"companyName\"]/text()')[0]\n",
    "    except Exception as e:\n",
    "        company_name = 'Not available'\n",
    "    return company_name\n",
    "\n",
    "\n",
    "# functions to extract the company location\n",
    "def get_company_location(job):\n",
    "    try:\n",
    "        company_location = job.xpath('./descendant::div[@class=\"companyLocation\"]/text()')[0]\n",
    "    except Exception as e:\n",
    "        company_location = 'Not available'\n",
    "    return company_location\n",
    "\n",
    "\n",
    "# functions to extract salary information\n",
    "def get_salary(job):\n",
    "    try:\n",
    "        salary = job.xpath('./descendant::span[@class=\"estimated-salary\"]/span/text()')\n",
    "    except Exception as e:\n",
    "        salary = 'Not available'\n",
    "    if len(salary) == 0:\n",
    "        try:\n",
    "            salary = job.xpath('./descendant::div[@class=\"metadata salary-snippet-container\"]/div/text()')[0]\n",
    "        except Exception as e:\n",
    "            salary = 'Not available'\n",
    "    else:\n",
    "        salary = salary[0]\n",
    "    return salary\n",
    "\n",
    "\n",
    "# functions to extract job type\n",
    "def get_job_type(job):\n",
    "    try:\n",
    "        job_type = job.xpath('./descendant::div[@class=\"metadata\"]/div/text()')[0]\n",
    "    except Exception as e:\n",
    "        job_type = 'Not available'\n",
    "    return job_type\n",
    "\n",
    "\n",
    "# functions to extract job rating\n",
    "def get_rating(job):\n",
    "    try:\n",
    "        rating = job.xpath('./descendant::span[@class=\"ratingNumber\"]/span/text()')[0]\n",
    "    except Exception as e:\n",
    "        rating = 'Not available'\n",
    "    return rating\n",
    "\n",
    "\n",
    "# functions to extract job description\n",
    "def get_job_desc(job):\n",
    "    try:\n",
    "        job_desc = job.xpath('./descendant::div[@class=\"job-snippet\"]/ul/li/text()')\n",
    "    except Exception as e:\n",
    "        job_desc = ['Not available']\n",
    "    if job_desc:\n",
    "        job_desc = \",\".join(job_desc)\n",
    "    else:\n",
    "        job_desc = 'Not available'\n",
    "    return job_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c9ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bc330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to extract job link\n",
    "def get_job_link(job):\n",
    "    practice_=[]\n",
    "    try:\n",
    "        job_link = job.xpath('./descendant::h2/a/@href')[0]\n",
    "    except Exception as e:\n",
    "        job_link = 'Not available'\n",
    "    practice_.append(job_link)\n",
    "#     return job_link\n",
    "    return practice_\n",
    "\n",
    "for job_keyword in job_search_keyword:\n",
    "    for location_keyword in location_search_keyword:\n",
    "        all_jobs = []\n",
    "        for page_no in range(0, 10, 10):\n",
    "            url = paginaton_url.format(job_keyword, location_keyword, page_no)\n",
    "            page_dom = get_dom(url)\n",
    "            jobs = page_dom.xpath('//div[@class=\"job_seen_beacon\"]')\n",
    "        all_jobs.append(jobs)\n",
    "#             all_jobs = all_jobs + jobs\n",
    "#     print(all_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73882025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c095a484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7905896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2445cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a746df1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a CSV file to write the job listings data\n",
    "# with open('indeed_jobs1.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "#     theWriter = writer(f)\n",
    "#     heading = ['job_link', 'job_title', 'company_name', 'company_location', 'salary', 'job_type', 'rating', 'job_description', 'searched_job', 'searched_location']\n",
    "#     theWriter.writerow(heading)\n",
    "#     for job_keyword in job_search_keyword:\n",
    "#         for location_keyword in location_search_keyword:\n",
    "#             all_jobs = []\n",
    "#             for page_no in range(0, 100, 10):\n",
    "#                 url = paginaton_url.format(job_keyword, location_keyword, page_no)\n",
    "#                 page_dom = get_dom(url)\n",
    "#                 jobs = page_dom.xpath('//div[@class=\"job_seen_beacon\"]')\n",
    "# #                 all_jobs = all_jobs +jobs\n",
    "#                 print(all_jobs+jobs)\n",
    "#                 all_jobs_ = all_jobs.append(jobs) #changed here and below\n",
    "#                 print(\"yay\",all_jobs_)\n",
    "#             for job in all_jobs_:\n",
    "#                 job_link = base_url + get_job_link(job)\n",
    "#                 time.sleep(2)\n",
    "#                 job_title = get_job_title(job)\n",
    "#                 time.sleep(2)\n",
    "#                 company_name = get_company_name(job)\n",
    "#                 time.sleep(2)\n",
    "#                 company_location = get_company_location(job)\n",
    "#                 time.sleep(2)\n",
    "#                 salary = get_salary(job)\n",
    "#                 time.sleep(2)\n",
    "#                 job_type = get_job_type(job)\n",
    "#                 time.sleep(2)\n",
    "#                 rating = get_rating(job)\n",
    "#                 time.sleep(2)\n",
    "#                 job_desc = get_job_desc(job)\n",
    "#                 time.sleep(2)\n",
    "#                 record = [job_link, job_title, company_name, company_location, salary, job_type, rating, job_desc, job_keyword, location_keyword]\n",
    "#                 theWriter.writerow(record)\n",
    "\n",
    "# # Closing the web browser\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06fb8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_keyword in job_search_keyword:\n",
    "    for location_keyword in location_search_keyword:\n",
    "#         print(job_keyword)\n",
    "        all_jobs = []\n",
    "        for page_no in range(0, 10, 10): # changed 0,100,10\n",
    "            url = paginaton_url.format(job_keyword, location_keyword, page_no)\n",
    "            page_dom = get_dom(url)\n",
    "            jobs = page_dom.xpath('//div[@class=\"job_seen_beacon\"]')\n",
    "#             all_jobs_ = all_jobs.append(jobs)\n",
    "            print(jobs.text)\n",
    "#             all_jobs_ = all_jobs+jobs #changed here and below\n",
    "#             print(\"yay\",all_jobs_)\n",
    "#         for job in all_jobs_:\n",
    "#             job_link = base_url + get_job_link(job)\n",
    "#             time.sleep(2)\n",
    "#             job_title = get_job_title(job)\n",
    "#             time.sleep(2)\n",
    "#             company_name = get_company_name(job)\n",
    "#             time.sleep(2)\n",
    "#             company_location = get_company_location(job)\n",
    "#             time.sleep(2)\n",
    "#             salary = get_salary(job)\n",
    "#             time.sleep(2)\n",
    "#             job_type = get_job_type(job)\n",
    "#             time.sleep(2)\n",
    "#             rating = get_rating(job)\n",
    "#             time.sleep(2)\n",
    "#             job_desc = get_job_desc(job)\n",
    "#             time.sleep(2)\n",
    "#             print(job_link,company_location,salary,job_type,rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52e07a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49893b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa12736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ff3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv('indeed_jobs1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e00647",
   "metadata": {},
   "source": [
    "# Like, Share & <font color=red>SUB</font>scribe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebeef3e",
   "metadata": {},
   "source": [
    "# `Citations & Help:`\n",
    "\n",
    "# ◔̯◔\n",
    "\n",
    "https://pypi.org/project/webdriver-manager/\n",
    "\n",
    "https://www.blog.datahut.co/post/scrape-indeed-using-selenium-and-beautifulsoup\n",
    "\n",
    "https://github.com/henrionantony/Dynamic-Web-Scraping-using-Python-and-Selenium/blob/master/indeed.py\n",
    "\n",
    "https://www.specrom.com/blog/web-scraping-job-postings-on-indeed-using-python/\n",
    "\n",
    "https://www.scrapingdog.com/blog/scrape-indeed-using-python/\n",
    "\n",
    "https://selenium-python.readthedocs.io/locating-elements.html#locating-elements\n",
    "\n",
    "https://stackoverflow.com/questions/50865088/how-to-get-string-dump-of-lxml-element\n",
    "\n",
    "https://selenium-python.readthedocs.io/navigating.html\n",
    "\n",
    "https://towardsdatascience.com/web-scraping-job-postings-from-indeed-com-using-selenium-5ae58d155daf\n",
    "\n",
    "https://www.pycodemates.com/2022/01/Indeed-jobs-scraping-with-python-bs4-selenium-and-pandas.html\n",
    "\n",
    "https://medium.com/forcodesake/how-to-build-a-scraping-tool-for-indeed-in-8-minutes-data-science-csv-selenium-beautifulsoup-python-95fcca4b9719\n",
    "\n",
    "https://www.tutorialspoint.com/how-to-open-browser-window-in-incognito-private-mode-using-python-selenium-webdriver\n",
    "\n",
    "https://www.selenium.dev/selenium/docs/api/py/webdriver/selenium.webdriver.common.keys.html\n",
    "\n",
    "https://pythonbasics.org/selenium-wait-for-page-to-load/\n",
    "\n",
    "https://www.seleniumeasy.com/selenium-tutorials/selenium-headless-browser-execution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
